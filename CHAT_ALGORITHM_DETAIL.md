    # ğŸ¤– UniZ ëŒ€í™” ì•Œê³ ë¦¬ì¦˜ - ì™„ì „ ìƒì„¸ ê°€ì´ë“œ

    **Agent ê¸°ë°˜ Function Calling ì‹œìŠ¤í…œ**

    ---

    ## ğŸ“‹ ëª©ì°¨

    1. [ì „ì²´ í”Œë¡œìš° ê°œìš”](#ì „ì²´-í”Œë¡œìš°-ê°œìš”)
    2. [Phase 1: ì‚¬ìš©ì ì…ë ¥ â†’ API ì „ì†¡](#phase-1-ì‚¬ìš©ì-ì…ë ¥--api-ì „ì†¡)
    3. [Phase 2: API ë¼ìš°í„° ì²˜ë¦¬](#phase-2-api-ë¼ìš°í„°-ì²˜ë¦¬)
    4. [Phase 3: ì—ì´ì „íŠ¸ ëŒ€í™” ì²˜ë¦¬ (í•µì‹¬)](#phase-3-ì—ì´ì „íŠ¸-ëŒ€í™”-ì²˜ë¦¬-í•µì‹¬)
    5. [Phase 4: ë¬¸ì„œ ê²€ìƒ‰ ì‹¤í–‰](#phase-4-ë¬¸ì„œ-ê²€ìƒ‰-ì‹¤í–‰)
    6. [Phase 5: ì‘ë‹µ ë°˜í™˜](#phase-5-ì‘ë‹µ-ë°˜í™˜)
    7. [ë°ì´í„° êµ¬ì¡°](#ë°ì´í„°-êµ¬ì¡°)

    ---

    ## ğŸ¯ ì „ì²´ í”Œë¡œìš° ê°œìš”

    ```
    ì‚¬ìš©ì ì…ë ¥
        â†“
    [Frontend] ChatPage.tsx::handleSend()
        â†“
    [Frontend] client.ts::sendMessage()
        â†“ POST /api/chat/
    [Backend] chat.py::chat()
        â†“
    [Backend] agent_service.py::chat()
        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Gemini Function Callâ”‚
        â”‚   (ìµœëŒ€ 5ë²ˆ ë£¨í”„)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
        â”œâ”€ [ì¼ë°˜ ëŒ€í™”] â†’ í…ìŠ¤íŠ¸ ì‘ë‹µ
        â”‚
        â””â”€ [ê²€ìƒ‰ í•„ìš”] â†’ search_documents() í˜¸ì¶œ
                â†“
            1. í•´ì‹œíƒœê·¸ ê¸°ë°˜ ë¬¸ì„œ í•„í„°ë§
            2. Geminië¡œ ìš”ì•½ë³¸ ë¶„ì„
            3. ì „ì²´ ë¬¸ì„œ ë¡œë“œ
            4. Gemini Liteë¡œ ì •ë³´ ì¶”ì¶œ
            5. Function Response ë°˜í™˜
                â†“
            ë‹¤ì‹œ Geminiì—ê²Œ ì „ë‹¬
                â†“
            ìµœì¢… ë‹µë³€ ìƒì„±
        â†“
    ì‚¬ìš©ìì—ê²Œ ì‘ë‹µ í‘œì‹œ
    ```

    ---

    ## Phase 1: ì‚¬ìš©ì ì…ë ¥ â†’ API ì „ì†¡

    ### ğŸ“ ìœ„ì¹˜: `frontend/src/pages/ChatPage.tsx`

    #### 1.1 ì‚¬ìš©ìê°€ ë©”ì‹œì§€ ì…ë ¥ í›„ ì „ì†¡ ë²„íŠ¼ í´ë¦­

    ```typescript
    // í•¨ìˆ˜: ChatPage::handleSend()
    const handleSend = async () => {
    if (!input.trim() || isLoading) return

    // 1. ì‚¬ìš©ì ë©”ì‹œì§€ ê°ì²´ ìƒì„±
    const userMessage: Message = {
        id: Date.now().toString(),
        text: input,
        isUser: true,
    }

    // 2. í™”ë©´ì— ì¦‰ì‹œ í‘œì‹œ
    setMessages((prev) => [...prev, userMessage])
    setInput('')
    setIsLoading(true)

    try {
        // 3. API í˜¸ì¶œ
        const response: ChatResponse = await sendMessage(input, sessionId)
        // ...
    }
    }
    ```

    **í˜¸ì¶œ ì²´ì¸:**
    - `handleSend()` â†’ `sendMessage(input, sessionId)`

    ---

    ### ğŸ“ ìœ„ì¹˜: `frontend/src/api/client.ts`

    #### 1.2 API í´ë¼ì´ì–¸íŠ¸ì—ì„œ HTTP ìš”ì²­ ì „ì†¡

    ```typescript
    // í•¨ìˆ˜: sendMessage()
    export async function sendMessage(
    message: string,
    sessionId: string = 'default'
    ): Promise<ChatResponse> {
    const response = await axios.post<ChatResponse>('/api/chat/', {
        message,
        session_id: sessionId
    })
    return response.data
    }
    ```

    **HTTP ìš”ì²­:**
    ```http
    POST /api/chat/
    Content-Type: application/json

    {
    "message": "ì„œìš¸ëŒ€ 2028 ì •ì‹œ ì•Œë ¤ì¤˜",
    "session_id": "session-1234567890"
    }
    ```

    ---

    ## Phase 2: API ë¼ìš°í„° ì²˜ë¦¬

    ### ğŸ“ ìœ„ì¹˜: `backend/routers/chat.py`

    #### 2.1 FastAPI ì—”ë“œí¬ì¸íŠ¸ ì§„ì…

    ```python
    # í•¨ìˆ˜: chat()
    @router.post("/", response_model=ChatResponse)
    async def chat(request: ChatRequest):
        """ì—ì´ì „íŠ¸ ê¸°ë°˜ ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬"""
        
        # 1. ì„¸ì…˜ ID ê°€ì ¸ì˜¤ê¸°
        session_id = request.session_id
        
        # 2. ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° (ì¸ë©”ëª¨ë¦¬ ì €ì¥ì†Œ)
        if session_id not in conversation_sessions:
            conversation_sessions[session_id] = []
        
        history = conversation_sessions[session_id]
        
        # 3. ì—ì´ì „íŠ¸ ì„œë¹„ìŠ¤ í˜¸ì¶œ â­ í•µì‹¬!
        result = await agent_service.chat(
            user_message=request.message,
            history=history
        )
        
        # 4. íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        history.append({"role": "user", "parts": [request.message]})
        history.append({"role": "model", "parts": [result["response"]]})
        
        # 5. ìµœê·¼ 10í„´ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ì ˆì•½)
        if len(history) > 20:
            conversation_sessions[session_id] = history[-20:]
        
        # 6. ì±„íŒ… ë¡œê·¸ DB ì €ì¥
        await supabase_service.insert_chat_log(
            request.message,
            result["response"],
            is_fact_mode=result["used_search"]
        )
        
        # 7. ì‘ë‹µ ë°˜í™˜
        return ChatResponse(
            response=result["response"],
            sources=result["sources"],
            source_urls=result.get("source_urls", [])
        )
    ```

    **í˜¸ì¶œ ì²´ì¸:**
    - `chat()` â†’ `agent_service.chat(user_message, history)`
    - `chat()` â†’ `supabase_service.insert_chat_log()`

    ---

    ## Phase 3: ì—ì´ì „íŠ¸ ëŒ€í™” ì²˜ë¦¬ (í•µì‹¬)

    ### ğŸ“ ìœ„ì¹˜: `backend/services/agent_service.py`

    #### 3.1 ì—ì´ì „íŠ¸ ëŒ€í™” ì‹œì‘

    ```python
    # í´ë˜ìŠ¤: AgentService
    # í•¨ìˆ˜: chat()
    @staticmethod
    async def chat(user_message: str, history: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ ê¸°ë°˜ ëŒ€í™” ì²˜ë¦¬
        """
        
        # 1. ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        if history is None:
            history = []
        
        # í˜„ì¬ ìš”ì²­ìš© messages (function call ë‚´ì—­ í¬í•¨)
        messages = history.copy() + [{"role": "user", "parts": [user_message]}]
        
        # 2. ì´ˆê¸°í™”
        sources = []
        source_urls = []
        used_search = False
        
        # 3. Tool ì‚¬ìš© ëŒ€í™” ë£¨í”„ (ìµœëŒ€ 5ë²ˆ)
        for turn in range(5):
            print(f"{'~'*80}")
            print(f"í„´ {turn + 1}")
            print(f"{'~'*80}")
            
            # 4. Gemini í˜¸ì¶œ (tools í¬í•¨) â­
            response = await gemini_service.chat_with_tools(
                messages=messages,
                tools=[AgentService.SEARCH_TOOL],
                system_instruction=AgentService.SYSTEM_INSTRUCTION
            )
            
            # 5. ì‘ë‹µ íƒ€ì… í™•ì¸
            if response["type"] == "text":
                # âœ… ìµœì¢… ë‹µë³€ (ê²€ìƒ‰ ì—†ì´ ë°”ë¡œ ë‹µë³€)
                return {
                    "response": response["content"],
                    "sources": sources,
                    "source_urls": source_urls,
                    "used_search": used_search
                }
            
            elif response["type"] == "function_call":
                # ğŸ”§ Function Call ë°œìƒ (ë¬¸ì„œ ê²€ìƒ‰ í•„ìš”)
                fc = response["function_call"]
                func_name = fc["name"]
                func_args = fc["args"]
                
                if func_name == "search_documents":
                    # 6. ë¬¸ì„œ ê²€ìƒ‰ ì‹¤í–‰ â­
                    search_result = await AgentService.search_documents(func_args["query"])
                    used_search = True
                    
                    if search_result["found"]:
                        sources.extend(search_result["sources"])
                        source_urls.extend(search_result.get("source_urls", []))
                        
                        # 7. Gemini Liteë¡œ ì •ë³´ ì¶”ì¶œ â­
                        extracted_info = await gemini_service.extract_info_from_documents(
                            query=func_args["query"],
                            documents=search_result['content'],
                            system_instruction="ë‹¹ì‹ ì€ ë¬¸ì„œì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                        )
                        
                        result_text = f"ê²€ìƒ‰ ê²°ê³¼:\n\n{extracted_info}"
                    else:
                        result_text = "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    
                    # 8. Function Response ìƒì„± (Gemini SDK í˜•ì‹)
                    from google.ai.generativelanguage_v1beta.types import content as glm_content
                    
                    # Function Callì„ ëŒ€í™”ì— ì¶”ê°€
                    messages.append({
                        "role": "model",
                        "parts": [response["raw_response"].candidates[0].content.parts[0]]
                    })
                    
                    # Function Response ì¶”ê°€
                    function_response = glm_content.Part(
                        function_response=glm_content.FunctionResponse(
                            name=func_name,
                            response={"result": result_text}
                        )
                    )
                    
                    messages.append({
                        "role": "user",
                        "parts": [function_response]
                    })
                    
                    # 9. ë‹¤ìŒ í„´ìœ¼ë¡œ (Geminiê°€ ì´ì œ ì¶”ì¶œëœ ì •ë³´ë¡œ ë‹µë³€ ìƒì„±)
                    continue
        
        # ìµœëŒ€ í„´ ì´ˆê³¼ (ë³´í†µ ì—¬ê¸°ê¹Œì§€ ì•ˆ ì˜´)
        return {
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.",
            "sources": sources,
            "source_urls": source_urls,
            "used_search": used_search
        }
    ```

    **í˜¸ì¶œ ì²´ì¸:**
    - `agent_service.chat()` â†’ `gemini_service.chat_with_tools()`
    - `agent_service.chat()` â†’ `AgentService.search_documents()` (ì¡°ê±´ë¶€)
    - `agent_service.chat()` â†’ `gemini_service.extract_info_from_documents()` (ì¡°ê±´ë¶€)

    ---

    #### 3.2 Gemini Function Calling

    ### ğŸ“ ìœ„ì¹˜: `backend/services/gemini_service.py`

    ```python
    # í´ë˜ìŠ¤: GeminiService
    # í•¨ìˆ˜: chat_with_tools()
    async def chat_with_tools(
        self,
        messages: List[Dict[str, Any]],
        tools: List[FunctionDeclaration],
        system_instruction: str = ""
    ) -> Dict[str, Any]:
        """Toolì„ ì‚¬ìš©í•œ Gemini ëŒ€í™”"""
        
        # 1. Tool ë˜í•‘
        tool_wrapper = Tool(function_declarations=tools)
        
        # 2. ëª¨ë¸ ìƒì„± (ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ í¬í•¨)
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 2048,
        }
        
        model = genai.GenerativeModel(
            GEMINI_FLASH_MODEL,  # "gemini-2.0-flash-exp"
            tools=[tool_wrapper],
            system_instruction=system_instruction if system_instruction else None,
            generation_config=generation_config
        )
        
        # 3. ëŒ€í™” ì„¸ì…˜ ì‹œì‘
        chat = model.start_chat(history=messages[:-1] if len(messages) > 1 else [])
        
        # 4. ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì „ì†¡
        last_message = messages[-1]["parts"][0]
        
        request_options = genai.types.RequestOptions(
            retry=None,
            timeout=30.0
        )
        
        response = chat.send_message(last_message, request_options=request_options)
        
        # 5. ì‘ë‹µ íŒŒì‹± (ë¹ˆ ì‘ë‹µ ì²´í¬)
        if not response.candidates or len(response.candidates) == 0:
            logger.warning("Gemini ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤")
            return {
                "type": "text",
                "content": "ì£„ì†¡í•©ë‹ˆë‹¤. AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "raw_response": response
            }
        
        candidate = response.candidates[0]
        
        # finish_reason í™•ì¸
        finish_reason = getattr(candidate, 'finish_reason', None)
        logger.info(f"Gemini finish_reason: {finish_reason}")
        
        if not candidate.content or not candidate.content.parts or len(candidate.content.parts) == 0:
            # SAFETY í•„í„° ì²´í¬
            if finish_reason and 'SAFETY' in str(finish_reason):
                return {
                    "type": "text",
                    "content": "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.",
                    "raw_response": response
                }
            
            return {
                "type": "text",
                "content": "ì£„ì†¡í•©ë‹ˆë‹¤. AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "raw_response": response
            }
        
        # 6. Function Call vs Text êµ¬ë¶„
        first_part = candidate.content.parts[0]
        
        if hasattr(first_part, 'function_call') and first_part.function_call and first_part.function_call.name:
            # ğŸ”§ Function Call ë°˜í™˜
            fc = first_part.function_call
            return {
                "type": "function_call",
                "function_call": {
                    "name": fc.name,
                    "args": dict(fc.args)
                },
                "raw_response": response
            }
        else:
            # ğŸ’¬ ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ
            return {
                "type": "text",
                "content": response.text.strip(),
                "raw_response": response
            }
    ```

    **ë°˜í™˜ ì˜ˆì‹œ:**

    **ì¼€ì´ìŠ¤ 1: ì¼ë°˜ ëŒ€í™” (ê²€ìƒ‰ ë¶ˆí•„ìš”)**
    ```python
    {
        "type": "text",
        "content": "ì„œìš¸ëŒ€ë¥¼ ëª©í‘œë¡œ í•˜ì‹œëŠ”êµ°ìš”! ì •ë§ ë©‹ì§„ ëª©í‘œì˜ˆìš”. í˜¹ì‹œ ìˆ˜ì‹œì™€ ì •ì‹œ ì¤‘ ì–´ëŠ ì „í˜•ì´ ë” ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
        "raw_response": <Response ê°ì²´>
    }
    ```

    **ì¼€ì´ìŠ¤ 2: Function Call (ê²€ìƒ‰ í•„ìš”)**
    ```python
    {
        "type": "function_call",
        "function_call": {
            "name": "search_documents",
            "args": {
                "query": "ì„œìš¸ëŒ€ 2028 ì •ì‹œ êµê³¼í‰ê°€"
            }
        },
        "raw_response": <Response ê°ì²´>
    }
    ```

    ---

    ## Phase 4: ë¬¸ì„œ ê²€ìƒ‰ ì‹¤í–‰

    ### ğŸ“ ìœ„ì¹˜: `backend/services/agent_service.py`

    #### 4.1 search_documents ë„êµ¬ ì‹¤í–‰

    ```python
    # í´ë˜ìŠ¤: AgentService
    # í•¨ìˆ˜: search_documents() - ì •ì  ë©”ì„œë“œ
    @staticmethod
    async def search_documents(query: str) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ê²€ìƒ‰ ë„êµ¬ ì‹¤í–‰
        
        Returns:
            {
                "found": bool,
                "content": str,
                "sources": List[str],
                "source_urls": List[str]
            }
        """
        
        try:
            client = supabase_service.get_client()
            
            # ============================================================
            # 1ë‹¨ê³„: documents_metadataì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
            # ============================================================
            print(f"   ğŸ“‹ [1ë‹¨ê³„] ì§ˆë¬¸ ë¶„ì„ ì¤‘...")
            
            metadata_response = client.table('documents_metadata').select('*').execute()
            
            if not metadata_response.data:
                return {"found": False, "content": "", "sources": [], "source_urls": []}
            
            # 1-1. ì§ˆë¬¸ì—ì„œ í•„ìˆ˜ ì¡°ê±´ ì¶”ì¶œ (ì—°ë„, ëŒ€í•™ëª…)
            query_lower = query.lower()
            import re
            
            required_year = None
            required_univ = None
            
            # ì—°ë„ ì¶”ì¶œ (í•„ìˆ˜)
            year_match = re.search(r'(2024|2025|2026|2027|2028)', query)
            if year_match:
                required_year = f'#{year_match.group()}'
                print(f"   âœ“ [í•„ìˆ˜] ì—°ë„ ê°ì§€: {required_year}")
            
            # ëŒ€í•™ëª… ì¶”ì¶œ (í•„ìˆ˜)
            universities = ['ì„œìš¸ëŒ€', 'ì—°ì„¸ëŒ€', 'ê³ ë ¤ëŒ€', ...]
            for univ in universities:
                if univ in query:
                    required_univ = f'#{univ}'
                    print(f"   âœ“ [í•„ìˆ˜] ëŒ€í•™ëª… ê°ì§€: {required_univ}")
                    break
            
            # ì„ íƒ ì¡°ê±´: ë¬¸ì„œ ì„±ê²©, ì „í˜• êµ¬ë¶„
            optional_hashtags = []
            
            if any(word in query for word in ['ìš”ê°•', 'ëª¨ì§‘', 'ì „í˜•']):
                optional_hashtags.append('#ëª¨ì§‘ìš”ê°•')
            elif any(word in query for word in ['ì…ê²°', 'ê²½ìŸë¥ ', 'ì»¤íŠ¸', 'í•©ê²©ì„ ']):
                optional_hashtags.append('#ì…ê²°í†µê³„')
            
            if 'ìˆ˜ì‹œ' in query:
                optional_hashtags.append('#ìˆ˜ì‹œ')
            if 'ì •ì‹œ' in query:
                optional_hashtags.append('#ì •ì‹œ')
            
            # ============================================================
            # 2ë‹¨ê³„: í•´ì‹œíƒœê·¸ ë§¤ì¹­ìœ¼ë¡œ ë¬¸ì„œ í•„í„°ë§
            # ============================================================
            print(f"\n   ğŸ“‹ [2ë‹¨ê³„] ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
            
            relevant_docs = []
            
            for doc in metadata_response.data:
                doc_hashtags = doc.get('hashtags', []) or []
                
                # âš ï¸ í•„ìˆ˜ ì¡°ê±´ ì²´í¬
                if required_year and required_year not in doc_hashtags:
                    continue  # ì—°ë„ ë¶ˆì¼ì¹˜ â†’ ì œì™¸
                
                if required_univ and required_univ not in doc_hashtags:
                    continue  # ëŒ€í•™ ë¶ˆì¼ì¹˜ â†’ ì œì™¸
                
                # ì ìˆ˜ ê³„ì‚°
                score = 0
                matched_info = []
                
                if required_year and required_year in doc_hashtags:
                    score += 20
                    matched_info.append(f"ì—°ë„ ì¼ì¹˜: {required_year}")
                
                if required_univ and required_univ in doc_hashtags:
                    score += 20
                    matched_info.append(f"ëŒ€í•™ ì¼ì¹˜: {required_univ}")
                
                # ì„ íƒ ì¡°ê±´ ë§¤ì¹­
                if doc_hashtags and optional_hashtags:
                    matching_optional = set(doc_hashtags) & set(optional_hashtags)
                    if matching_optional:
                        score += len(matching_optional) * 5
                
                if score > 0:
                    print(f"   â€¢ {doc.get('title')} (ì ìˆ˜: {score})")
                    relevant_docs.append((score, doc))
            
            # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
            relevant_docs.sort(key=lambda x: x[0], reverse=True)
            relevant_docs = [doc for score, doc in relevant_docs]
            
            if not relevant_docs:
                print("   âŒ ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ")
                return {"found": False, "content": "", "sources": [], "source_urls": []}
            
            print(f"\n   âœ… í•´ì‹œíƒœê·¸ ë§¤ì¹­: {len(relevant_docs)}ê°œ ë¬¸ì„œ í›„ë³´")
            
            # ============================================================
            # 3ë‹¨ê³„: ìš”ì•½ë³¸(ëª©ì°¨) ê¸°ë°˜ 2ì°¨ í•„í„°ë§ (Gemini)
            # ============================================================
            print(f"\n   ğŸ“‹ [3ë‹¨ê³„] ìš”ì•½ë³¸ ê¸°ë°˜ ë¬¸ì„œ ì„ ë³„ ì¤‘...")
            
            # í›„ë³´ ë¬¸ì„œë“¤ì˜ ìš”ì•½ë³¸ ëª©ë¡ ìƒì„±
            docs_summary_list = []
            for idx, doc in enumerate(relevant_docs[:10], 1):
                title = doc.get('title', 'ì œëª© ì—†ìŒ')
                summary = doc.get('summary', 'ìš”ì•½ ì—†ìŒ')
                hashtags = doc.get('hashtags', [])
                docs_summary_list.append(
                    f"{idx}. ì œëª©: {title}\n   í•´ì‹œíƒœê·¸: {', '.join(hashtags)}\n   ìš”ì•½: {summary[:500]}"
                )
            
            docs_summary_text = "\n\n".join(docs_summary_list)
            
            # Geminië¡œ ìš”ì•½ë³¸ ê¸°ë°˜ ë¬¸ì„œ ì„ ë³„
            filter_prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì˜ ìš”ì•½ë³¸(ëª©ì°¨)ì„ ì½ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° í•„ìš”í•œ ì •ë³´ê°€ ìˆëŠ” ë¬¸ì„œë§Œ ì„ íƒí•˜ì„¸ìš”.

    ì‚¬ìš©ì ì§ˆë¬¸: "{query}"

    ë¬¸ì„œ ëª©ë¡:
    {docs_summary_text}

    **ì„ íƒ ê¸°ì¤€:**
    1. ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° í•„ìš”í•œ êµ¬ì²´ì ì¸ ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ì„œë§Œ ì„ íƒ
    2. ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œëŠ” ì œì™¸
    3. ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì„ íƒ

    **ë‹µë³€ í˜•ì‹:**
    ê´€ë ¨ ë¬¸ì„œê°€ ìˆìœ¼ë©´: ë²ˆí˜¸ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„ (ì˜ˆ: 1, 3)
    ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìœ¼ë©´: ì—†ìŒ"""
            
            try:
                filter_result = await gemini_service.generate(
                    filter_prompt,
                    "ë‹¹ì‹ ì€ ë¬¸ì„œ í•„í„°ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                )
                
                if not filter_result.strip():
                    # ë¹ˆ ì‘ë‹µ â†’ fallback
                    selected_docs = relevant_docs[:3]
                elif "ì—†ìŒ" in filter_result.lower():
                    return {"found": False, "content": "", "sources": [], "source_urls": []}
                else:
                    # ë²ˆí˜¸ ì¶”ì¶œ
                    import re
                    selected_indices = [int(n.strip())-1 for n in re.findall(r'\d+', filter_result)]
                    selected_docs = [relevant_docs[i] for i in selected_indices if i < len(relevant_docs)]
                    
                    if not selected_docs:
                        selected_docs = relevant_docs[:3]
            
            except Exception as e:
                print(f"   âš ï¸ Gemini ìš”ì•½ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                selected_docs = relevant_docs[:3]
            
            # ============================================================
            # 4ë‹¨ê³„: ì„ ë³„ëœ ë¬¸ì„œì˜ ì „ì²´ ì²­í¬ ê°€ì ¸ì˜¤ê¸°
            # ============================================================
            print(f"\n   ğŸ“‹ [4ë‹¨ê³„] ë¬¸ì„œ ë‚´ìš© ë¡œë“œ ì¤‘...")
            
            full_content = ""
            sources = []
            source_urls = []
            
            for idx, doc in enumerate(selected_docs, 1):
                filename = doc['file_name']
                title = doc['title']
                file_url = doc.get('file_url') or ''
                
                sources.append(title)
                source_urls.append(file_url)
                
                print(f"   [{idx}] ğŸ“„ {title}")
                
                # í•´ë‹¹ ë¬¸ì„œì˜ ëª¨ë“  ì²­í¬ ê°€ì ¸ì˜¤ê¸°
                chunks_response = client.table('policy_documents')\
                    .select('content, metadata')\
                    .eq('metadata->>fileName', filename)\
                    .execute()
                
                if chunks_response.data:
                    # ì²­í¬ ìˆœì„œëŒ€ë¡œ ì •ë ¬
                    sorted_chunks = sorted(
                        chunks_response.data,
                        key=lambda x: x.get('metadata', {}).get('chunkIndex', 0)
                    )
                    
                    print(f"       ì²­í¬ ìˆ˜: {len(sorted_chunks)}ê°œ")
                    
                    full_content += f"\n\n{'='*60}\n"
                    full_content += f"ğŸ“„ {title}\n"
                    full_content += f"{'='*60}\n\n"
                    
                    for chunk in sorted_chunks:
                        full_content += chunk['content']
                        full_content += "\n\n"
            
            print(f"\n   ğŸ“Š ë¡œë“œëœ ë¬¸ì„œ ë‚´ìš©:")
            print(f"       ì„ ë³„ëœ ë¬¸ì„œ ìˆ˜: {len(selected_docs)}ê°œ")
            print(f"       ì´ ê¸¸ì´: {len(full_content):,}ì")
            
            return {
                "found": True,
                "content": full_content,
                "sources": sources,
                "source_urls": source_urls
            }
        
        except Exception as e:
            print(f"   âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return {"found": False, "content": "", "sources": [], "source_urls": []}
    ```

    **í˜¸ì¶œ ì²´ì¸:**
    - `search_documents()` â†’ `supabase_service.get_client()` (DB ì ‘ì†)
    - `search_documents()` â†’ `client.table('documents_metadata').select('*').execute()` (ë©”íƒ€ë°ì´í„° ì¡°íšŒ)
    - `search_documents()` â†’ `gemini_service.generate()` (ìš”ì•½ë³¸ ë¶„ì„)
    - `search_documents()` â†’ `client.table('policy_documents').select().eq().execute()` (ì²­í¬ ì¡°íšŒ)

    ---

    #### 4.2 Gemini Liteë¡œ ì •ë³´ ì¶”ì¶œ

    ### ğŸ“ ìœ„ì¹˜: `backend/services/gemini_service.py`

    ```python
    # í´ë˜ìŠ¤: GeminiService
    # í•¨ìˆ˜: extract_info_from_documents()
    async def extract_info_from_documents(
        self,
        query: str,
        documents: str,
        system_instruction: str = ""
    ) -> str:
        """
        Lite ëª¨ë¸ë¡œ ëŒ€ìš©ëŸ‰ ë¬¸ì„œì—ì„œ ì •ë³´ ì¶”ì¶œ (ë¹ ë¥¸ ì²˜ë¦¬)
        """
        
        prompt = f"""ë‹¤ìŒ ë¬¸ì„œì—ì„œ '{query}'ì— ëŒ€í•œ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

    ë¬¸ì„œ:
    {documents}

    ìš”êµ¬ì‚¬í•­:
    - ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œ ì •í™•í•˜ê²Œ ì¶”ì¶œ
    - ë¶ˆí•„ìš”í•œ ë‚´ìš©ì€ ì œì™¸
    - ì›ë¬¸ì˜ í‘œí˜„ì„ ìµœëŒ€í•œ ìœ ì§€
    - ê°„ê²°í•˜ê²Œ ì •ë¦¬ (1000ì ì´ë‚´)

    ì¶”ì¶œëœ ì •ë³´:"""
        
        if system_instruction:
            full_prompt = f"{system_instruction}\n\n{prompt}"
        else:
            full_prompt = prompt
        
        request_options = genai.types.RequestOptions(
            retry=None,
            timeout=30.0
        )
        
        # Lite ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ì²˜ë¦¬
        response = self.lite_model.generate_content(full_prompt, request_options=request_options)
        return response.text.strip()
    ```

    **ì‚¬ìš© ëª¨ë¸:**
    - `gemini-2.0-flash-thinking-exp-01-21` (Lite ëª¨ë¸)
    - ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ì— ìµœì í™”
    - ë¹ ë¥¸ ì‘ë‹µ ì†ë„

    ---

    ## Phase 5: ì‘ë‹µ ë°˜í™˜

    ### 5.1 ì—ì´ì „íŠ¸ì—ì„œ ìµœì¢… ë‹µë³€ ìƒì„±

    Phase 3ì˜ ë£¨í”„ì—ì„œ ì •ë³´ ì¶”ì¶œ í›„, `messages`ì— Function Responseë¥¼ ì¶”ê°€í•˜ê³  ë‹¤ì‹œ Geminië¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

    ```python
    # agent_service.py::chat() ë‚´ë¶€

    # Function Responseê°€ messagesì— ì¶”ê°€ëœ ìƒíƒœ
    messages = [
        {"role": "user", "parts": ["ì„œìš¸ëŒ€ 2028 ì •ì‹œ ì•Œë ¤ì¤˜"]},
        {"role": "model", "parts": [<function_call object>]},  # Function Call
        {"role": "user", "parts": [<function_response object>]}  # Function Response (ì¶”ì¶œëœ ì •ë³´)
    ]

    # ë‹¤ìŒ í„´ìœ¼ë¡œ ëŒì•„ê°€ì„œ ë‹¤ì‹œ Gemini í˜¸ì¶œ
    response = await gemini_service.chat_with_tools(...)

    # ì´ë²ˆì—” typeì´ "text"ë¡œ ë°˜í™˜ë¨
    if response["type"] == "text":
        return {
            "response": response["content"],  # ìµœì¢… ë‹µë³€ (cite íƒœê·¸ í¬í•¨)
            "sources": sources,  # ["2028í•™ë…„ë„ ëŒ€ì… ê¸°ë³¸ì‚¬í•­", ...]
            "source_urls": source_urls,  # ["https://...", ...]
            "used_search": True
        }
    ```

    ---

    ### 5.2 API ë¼ìš°í„°ì—ì„œ ì‘ë‹µ ë°˜í™˜

    ```python
    # routers/chat.py::chat()

    result = await agent_service.chat(...)  # Phase 3ì˜ ê²°ê³¼

    return ChatResponse(
        response=result["response"],
        sources=result["sources"],
        source_urls=result.get("source_urls", [])
    )
    ```

    **HTTP ì‘ë‹µ:**
    ```json
    {
    "response": "ë„¤, ì¤‘ìš”í•œ ë³€í™”ê°€ ìˆì–´ìš”. <cite>2028í•™ë…„ë„ë¶€í„° ì„œìš¸ëŒ€ ì •ì‹œì—ì„œëŠ” í•™ìƒë¶€ êµê³¼í‰ê°€ê°€ 40% ë°˜ì˜ë©ë‹ˆë‹¤</cite>. ë‹¤ë¥¸ ë³€ê²½ì‚¬í•­ë„ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
    "sources": ["2028í•™ë…„ë„ ëŒ€ì… ê¸°ë³¸ì‚¬í•­"],
    "source_urls": ["https://supabase.co/storage/.../abc123.pdf"],
    "debug_logs": []
    }
    ```

    ---

    ### 5.3 í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‘ë‹µ í‘œì‹œ

    ```typescript
    // ChatPage.tsx::handleSend() ë‚´ë¶€

    const response: ChatResponse = await sendMessage(input, sessionId)

    const botMessage: Message = {
    id: (Date.now() + 1).toString(),
    text: response.response,
    isUser: false,
    sources: response.sources,
    source_urls: response.source_urls,
    }

    setMessages((prev) => [...prev, botMessage])
    ```

    ---

    ## ğŸ“Š ë°ì´í„° êµ¬ì¡°

    ### Message êµ¬ì¡° (Gemini SDK)

    ```python
    # Geminiì—ê²Œ ì „ë‹¬ë˜ëŠ” messages í˜•ì‹
    [
        {
            "role": "user",
            "parts": ["ì‚¬ìš©ì ë©”ì‹œì§€"]
        },
        {
            "role": "model",
            "parts": ["AI ì‘ë‹µ"]
        },
        {
            "role": "user",
            "parts": ["ë‹¤ìŒ ì‚¬ìš©ì ë©”ì‹œì§€"]
        }
    ]
    ```

    ### Function Declaration (Tool ì •ì˜)

    ```python
    # agent_service.py::SEARCH_TOOL
    SEARCH_TOOL = FunctionDeclaration(
        name="search_documents",
        description=(
            "ëŒ€í•™ ì…ì‹œ ê´€ë ¨ ê³µì‹ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. "
            "êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ë‚ ì§œ, ê·œì •, ì „í˜• ë°©ë²• ë“± ì •í™•í•œ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ì¼ë°˜ì ì¸ ìœ„ë¡œë‚˜ ê²©ë ¤ëŠ” ê²€ìƒ‰ ì—†ì´ ë‹µë³€í•˜ì„¸ìš”."
        ),
        parameters={
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì˜ˆ: '2028í•™ë…„ë„ ì„œìš¸ëŒ€ ì •ì‹œ êµê³¼í‰ê°€')"
                }
            },
            "required": ["query"]
        }
    )
    ```

    ### System Instruction

    ```python
    SYSTEM_INSTRUCTION = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ëŒ€í•™ ì…ì‹œ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

    ğŸš« ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­:
    1. ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì‚¬ìš© ê¸ˆì§€
    2. í•œ ë²ˆì— ë§ì€ ì •ë³´ë¥¼ ìŸì•„ë‚´ì§€ ë§ˆì„¸ìš”
    3. ë§‰ì—°í•œ ì§ˆë¬¸ì— ë°”ë¡œ ê²€ìƒ‰í•˜ì§€ ë§ˆì„¸ìš”

    âš ï¸ ê²€ìƒ‰ íƒ€ì´ë° íŒë‹¨:
    ë§‰ì—°í•œ ì§ˆë¬¸: "ì„œìš¸ëŒ€ ê°€ê³ ì‹¶ì–´" â†’ ê²€ìƒ‰ X, êµ¬ì²´í™” ìœ ë„
    êµ¬ì²´ì ì¸ ì§ˆë¬¸: "ì„œìš¸ëŒ€ 2028 ì •ì‹œ ë³€ê²½ì‚¬í•­" â†’ ê²€ìƒ‰ O

    âœ… ì¶œì²˜ í‘œì‹œ (<cite> íƒœê·¸):
    - ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ë‚´ìš©ë§Œ <cite>ë¡œ ê°ì‹¸ê¸°
    - ì¶œì²˜ ê°œìˆ˜ì™€ <cite> ê°œìˆ˜ ì •í™•íˆ ì¼ì¹˜
    - ì¼ë°˜ ì¡°ì–¸/ê²©ë ¤ëŠ” <cite> ì‚¬ìš© ê¸ˆì§€

    ì˜ˆì‹œ:
    "<cite>2028í•™ë…„ë„ë¶€í„° ì„œìš¸ëŒ€ ì •ì‹œì—ì„œëŠ” í•™ìƒë¶€ êµê³¼í‰ê°€ê°€ 40% ë°˜ì˜ë©ë‹ˆë‹¤</cite>."
    """
    ```

    ---

    ## ğŸ”„ ì „ì²´ í•¨ìˆ˜ í˜¸ì¶œ ì²´ì¸ ìš”ì•½

    ```
    1. ChatPage.tsx::handleSend()
        â†“
    2. client.ts::sendMessage()
        â†“ HTTP POST /api/chat/
    3. chat.py::chat()
        â†“
    4. agent_service.py::chat()
        â†“
    5. gemini_service.py::chat_with_tools()
        â†“
        â”œâ”€ [ì¼ë°˜ ëŒ€í™”] â†’ 6a. response["type"] == "text" â†’ ë
        â”‚
        â””â”€ [ê²€ìƒ‰ í•„ìš”] â†’ 6b. response["type"] == "function_call"
                â†“
            7. agent_service.py::search_documents()
                â†“
                â”œâ”€ 8a. supabase_service.get_client()
                â”œâ”€ 8b. client.table('documents_metadata').select().execute()
                â”œâ”€ 8c. gemini_service.generate() (ìš”ì•½ë³¸ ë¶„ì„)
                â””â”€ 8d. client.table('policy_documents').select().execute()
                â†“
            9. gemini_service.py::extract_info_from_documents()
                â†“
            10. Function Response ìƒì„± â†’ messagesì— ì¶”ê°€
                â†“
            11. ë‹¤ì‹œ gemini_service.py::chat_with_tools() í˜¸ì¶œ
                â†“
            12. response["type"] == "text" (ìµœì¢… ë‹µë³€)
                â†“
    13. chat.py::chat() â†’ ChatResponse ë°˜í™˜
        â†“
    14. client.ts::sendMessage() â†’ response ë°›ìŒ
        â†“
    15. ChatPage.tsx::handleSend() â†’ í™”ë©´ì— í‘œì‹œ
    ```

    ---

    ## ğŸ¯ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ íŠ¹ì§•

    ### 1. **Agent ê¸°ë°˜ ëŒ€í™”**
    - LLMì´ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì—¬ ê²€ìƒ‰ ì—¬ë¶€ ê²°ì •
    - ë§‰ì—°í•œ ì§ˆë¬¸ â†’ êµ¬ì²´í™” ìœ ë„ (ê²€ìƒ‰ X)
    - êµ¬ì²´ì ì¸ ì§ˆë¬¸ â†’ ë¬¸ì„œ ê²€ìƒ‰ (ê²€ìƒ‰ O)

    ### 2. **6ë‹¨ê³„ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜**
    1. ì§ˆë¬¸ ë¶„ì„ (ì—°ë„, ëŒ€í•™ëª…, ì „í˜• ë“± ì¶”ì¶œ)
    2. í•´ì‹œíƒœê·¸ ê¸°ë°˜ ë¬¸ì„œ í•„í„°ë§ (í•„ìˆ˜ ì¡°ê±´ ì²´í¬)
    3. Geminië¡œ ìš”ì•½ë³¸ ë¶„ì„ (2ì°¨ í•„í„°ë§)
    4. ì „ì²´ ë¬¸ì„œ ë¡œë“œ (ì„ ë³„ëœ ë¬¸ì„œì˜ ëª¨ë“  ì²­í¬)
    5. Gemini Liteë¡œ ì •ë³´ ì¶”ì¶œ (ë¹ ë¥¸ ì²˜ë¦¬)
    6. Function Response ë°˜í™˜

    ### 3. **Function Calling ë£¨í”„**
    - ìµœëŒ€ 5ë²ˆ ë°˜ë³µ
    - Function Call â†’ Function Response â†’ ë‹¤ì‹œ LLM í˜¸ì¶œ
    - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ìœ ì§€

    ### 4. **ì¶œì²˜ í‘œì‹œ**
    - `<cite>` íƒœê·¸ë¡œ ê²€ìƒ‰ëœ ì •ë³´ ë§ˆí‚¹
    - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ íŒŒë€ìƒ‰ ë°°ê²½ìœ¼ë¡œ í‘œì‹œ
    - ë‹¤ìš´ë¡œë“œ URL ì œê³µ

    ---

    ## ğŸ“Œ ì£¼ìš” ì„¤ì •ê°’

    | í•­ëª© | ê°’ | ì„¤ëª… |
    |------|-----|------|
    | **Gemini ëª¨ë¸ (ëŒ€í™”)** | `gemini-2.0-flash-exp` | Function Calling ì§€ì› |
    | **Gemini ëª¨ë¸ (ë¬¸ì„œ)** | `gemini-2.0-flash-thinking-exp-01-21` | ë¹ ë¥¸ ì •ë³´ ì¶”ì¶œ |
    | **Temperature** | 0.7 | ì ì ˆí•œ ì°½ì˜ì„± |
    | **Max Output Tokens** | 2048 | ì¶©ë¶„í•œ ë‹µë³€ ê¸¸ì´ |
    | **ìµœëŒ€ ë£¨í”„** | 5í„´ | Function Call ë°˜ë³µ ì œí•œ |
    | **íˆìŠ¤í† ë¦¬ ìœ ì§€** | ìµœê·¼ 10í„´ (20ê°œ ë©”ì‹œì§€) | ë©”ëª¨ë¦¬ ì ˆì•½ |
    | **íƒ€ì„ì•„ì›ƒ** | 30ì´ˆ | API í˜¸ì¶œ ì œí•œ |

    ---

    ì´ ë¬¸ì„œëŠ” UniZ í”„ë¡œì íŠ¸ì˜ ëŒ€í™” ì•Œê³ ë¦¬ì¦˜ì„ **í•¨ìˆ˜ í˜¸ì¶œ ìˆ˜ì¤€**ê¹Œì§€ ì™„ì „íˆ ë¶„ì„í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. ê° ë‹¨ê³„ì—ì„œ ì–´ë–¤ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ê³ , ì–´ë–¤ ë°ì´í„°ê°€ ì „ë‹¬ë˜ëŠ”ì§€ ì •í™•í•˜ê²Œ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
