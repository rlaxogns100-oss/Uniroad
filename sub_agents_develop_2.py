"""
Sub Agents
- ëŒ€í•™ë³„ Agent: Supabaseì—ì„œ í•´ë‹¹ ëŒ€í•™ í•´ì‹œíƒœê·¸ ë¬¸ì„œ ê²€ìƒ‰
- ì»¨ì„¤íŒ… Agent: ì„ì‹œ DBì—ì„œ ì…ê²°/í™˜ì‚°ì ìˆ˜ ë°ì´í„° ì¡°íšŒ
- ì„ ìƒë‹˜ Agent: í•™ìŠµ ê³„íš ë° ë©˜íƒˆ ê´€ë¦¬ ì¡°ì–¸
"""

import google.generativeai as genai
from typing import Dict, Any, List
import json
import os
import re
from dotenv import load_dotenv
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))
from token_logger import log_token_usage

from services.supabase_client import supabase_service
from services.gemini_service import gemini_service
from .mock_database import (
    get_admission_data_by_grade,
    get_jeongsi_data_by_percentile,
    get_score_conversion_info,
    get_all_universities_data,
    ADMISSION_DATA_SUSI,
    ADMISSION_DATA_JEONGSI
)

# ë¡œê·¸ ì½œë°± (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìš©)
_log_callback = None

def set_log_callback(callback):
    """ë¡œê·¸ ì½œë°± ì„¤ì •"""
    global _log_callback
    _log_callback = callback

def _log(msg: str):
    """ë¡œê·¸ ì¶œë ¥ ë° ì½œë°± í˜¸ì¶œ"""
    if _log_callback:
        _log_callback(msg)
    else:
        print(msg)

load_dotenv()

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)


class SubAgentBase:
    """Sub Agent ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, name: str, description: str, custom_system_prompt: str = None):
        self.name = name
        self.description = description
        self.custom_system_prompt = custom_system_prompt
        self.model = genai.GenerativeModel(
            model_name="gemini-3-flash-preview",
        )

    async def execute(self, query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ì‹¤í–‰ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        raise NotImplementedError


class UniversityAgent(SubAgentBase):
    """
    ëŒ€í•™ë³„ Agent - Supabaseì—ì„œ í•´ë‹¹ ëŒ€í•™ í•´ì‹œíƒœê·¸ ë¬¸ì„œ ê²€ìƒ‰
    
    ê²€ìƒ‰ ë¡œì§:
    1. í•´ì‹œíƒœê·¸ë¡œ 1ì°¨ íƒìƒ‰ (#{ëŒ€í•™ëª…})
    2. ìš”ì•½ë³¸(500ì) ë¶„ì„ìœ¼ë¡œ ì í•©í•œ ë¬¸ì„œ ì„ ë³„
    3. ì„ ë³„ëœ ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš© ë¡œë“œ
    4. ì •ë³´ ì¶”ì¶œ í›„ ì¶œì²˜ì™€ í•¨ê»˜ ë°˜í™˜
    """

    SUPPORTED_UNIVERSITIES = ["ì„œìš¸ëŒ€", "ì—°ì„¸ëŒ€", "ê³ ë ¤ëŒ€", "ì„±ê· ê´€ëŒ€", "ê²½í¬ëŒ€"]

    def __init__(self, university_name: str, custom_system_prompt: str = None):
        self.university_name = university_name
        super().__init__(
            name=f"{university_name} agent",
            description=f"{university_name} ì…ì‹œ ì •ë³´(ì…ê²°, ëª¨ì§‘ìš”ê°•, ì „í˜•ë³„ ì •ë³´)ë¥¼ Supabaseì—ì„œ ê²€ìƒ‰í•˜ëŠ” ì—ì´ì „íŠ¸",
            custom_system_prompt=custom_system_prompt
        )

    async def execute(self, query: str) -> Dict[str, Any]:
        """ëŒ€í•™ ì •ë³´ ê²€ìƒ‰ ë° ì •ë¦¬"""
        _log("")
        _log("="*60)
        _log(f"ğŸ« {self.name} ì‹¤í–‰")
        _log("="*60)
        _log(f"ì¿¼ë¦¬: {query}")

        try:
            client = supabase_service.get_client()

            # ============================================================
            # 1ë‹¨ê³„: í•´ì‹œíƒœê·¸ë¡œ 1ì°¨ íƒìƒ‰
            # ============================================================
            _log("")
            _log(f"ğŸ“‹ [1ë‹¨ê³„] í•´ì‹œíƒœê·¸ ê²€ìƒ‰: #{self.university_name}")
            
            metadata_response = client.table('documents_metadata').select('*').execute()
            
            if not metadata_response.data:
                return {
                    "agent": self.name,
                    "status": "no_data",
                    "result": f"{self.university_name} ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "source_urls": [],
                    "citations": []
                }

            # í•´ì‹œíƒœê·¸ í•„í„°ë§
            required_univ_tag = f"#{self.university_name}"
            
            # ì¶”ê°€ í•´ì‹œíƒœê·¸ ì¶”ì¶œ (ì—°ë„, ì „í˜• ë“±)
            optional_tags = []
            year_match = re.search(r'(2024|2025|2026|2027|2028)', query)
            if year_match:
                optional_tags.append(f"#{year_match.group()}")
            
            if 'ìˆ˜ì‹œ' in query:
                optional_tags.append('#ìˆ˜ì‹œ')
            if 'ì •ì‹œ' in query:
                optional_tags.append('#ì •ì‹œ')
            if any(word in query for word in ['ìš”ê°•', 'ëª¨ì§‘']):
                optional_tags.append('#ëª¨ì§‘ìš”ê°•')
            if any(word in query for word in ['ì…ê²°', 'ê²½ìŸë¥ ', 'ì»¤íŠ¸']):
                optional_tags.append('#ì…ê²°í†µê³„')

            # í•„í„°ë§
            relevant_docs = []
            for doc in metadata_response.data:
                doc_hashtags = doc.get('hashtags', []) or []
                
                # í•„ìˆ˜ ì¡°ê±´: ëŒ€í•™ íƒœê·¸ í¬í•¨
                if required_univ_tag not in doc_hashtags:
                    continue
                
                # ì ìˆ˜ ê³„ì‚°
                score = 10  # ëŒ€í•™ íƒœê·¸ ì¼ì¹˜ ê¸°ë³¸ ì ìˆ˜
                for tag in optional_tags:
                    if tag in doc_hashtags:
                        score += 5
                
                relevant_docs.append((score, doc))
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            relevant_docs.sort(key=lambda x: x[0], reverse=True)
            relevant_docs = [doc for score, doc in relevant_docs]
            
            _log(f"   {self.university_name} ê´€ë ¨ ë¬¸ì„œ: {len(relevant_docs)}ê°œ")
            
            if not relevant_docs:
                return {
                    "agent": self.name,
                    "status": "no_match",
                    "result": f"{self.university_name} ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "source_urls": [],
                    "citations": []
                }

            # ============================================================
            # 2ë‹¨ê³„: ìš”ì•½ë³¸ ë¶„ì„ (500ì ì´ë‚´)
            # ============================================================
            _log("")
            _log(f"ğŸ“‹ [2ë‹¨ê³„] ìš”ì•½ë³¸ ë¶„ì„")
            
            docs_summary_list = []
            for idx, doc in enumerate(relevant_docs[:10], 1):  # ìµœëŒ€ 10ê°œ
                title = doc.get('title', 'ì œëª© ì—†ìŒ')
                summary = doc.get('summary', 'ìš”ì•½ ì—†ìŒ')[:500]
                hashtags = doc.get('hashtags', [])
                docs_summary_list.append(
                    f"{idx}. ì œëª©: {title}\n   í•´ì‹œíƒœê·¸: {', '.join(hashtags) if hashtags else 'ì—†ìŒ'}\n   ìš”ì•½: {summary}"
                )
            
            docs_summary_text = "\n\n".join(docs_summary_list)
            
            filter_prompt = f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì˜ ìš”ì•½ë³¸ì„ ì½ê³ , ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° í•„ìš”í•œ ë¬¸ì„œë§Œ ì„ íƒí•˜ì„¸ìš”.

ì§ˆë¬¸: "{query}"

ë¬¸ì„œ ëª©ë¡:
{docs_summary_text}

ì„ íƒ ê¸°ì¤€:
1. ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° í•„ìš”í•œ ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ì„œë§Œ ì„ íƒ
2. ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì„ íƒ

ë‹µë³€ í˜•ì‹:
ê´€ë ¨ ë¬¸ì„œê°€ ìˆìœ¼ë©´: ë²ˆí˜¸ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„ (ì˜ˆ: 1, 3)
ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìœ¼ë©´: ì—†ìŒ"""

            try:
                filter_result = await gemini_service.generate(
                    filter_prompt,
                    "ë¬¸ì„œ í•„í„°ë§ ì „ë¬¸ê°€"
                )
                
                if not filter_result.strip() or "ì—†ìŒ" in filter_result.lower():
                    # í•„í„°ë§ ì‹¤íŒ¨ì‹œ ìƒìœ„ 2ê°œ ì‚¬ìš©
                    selected_docs = relevant_docs[:2]
                else:
                    selected_indices = [int(n.strip())-1 for n in re.findall(r'\d+', filter_result)]
                    selected_docs = [relevant_docs[i] for i in selected_indices if i < len(relevant_docs)]
                    if not selected_docs:
                        selected_docs = relevant_docs[:2]
                        
            except Exception as e:
                _log(f"   âš ï¸ ìš”ì•½ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                selected_docs = relevant_docs[:2]
            
            _log(f"   ì„ ë³„ëœ ë¬¸ì„œ: {len(selected_docs)}ê°œ")

            # ============================================================
            # 3ë‹¨ê³„: ì „ì²´ ë‚´ìš© ë¡œë“œ
            # ============================================================
            _log("")
            _log(f"ğŸ“‹ [3ë‹¨ê³„] ë¬¸ì„œ ë‚´ìš© ë¡œë“œ")
            
            full_content = ""
            sources = []
            source_urls = []
            citations = []
            
            for doc in selected_docs:
                filename = doc['file_name']
                title = doc['title']
                file_url = doc.get('file_url') or ''
                
                sources.append(title)
                source_urls.append(file_url)
                
                _log(f"   ğŸ“„ {title}")
                
                # ì²­í¬ ê°€ì ¸ì˜¤ê¸°
                chunks_response = client.table('policy_documents')\
                    .select('id, content, metadata')\
                    .eq('metadata->>fileName', filename)\
                    .execute()
                
                if chunks_response.data:
                    sorted_chunks = sorted(
                        chunks_response.data,
                        key=lambda x: x.get('metadata', {}).get('chunkIndex', 0)
                    )
                    
                    full_content += f"\n\n{'='*60}\n"
                    full_content += f"ğŸ“„ {title}\n"
                    full_content += f"{'='*60}\n\n"
                    
                    # ì²­í¬ ì •ë³´ ì €ì¥ (ë‹µë³€ ì¶”ì ìš©)
                    for chunk in sorted_chunks:
                        chunk_content = chunk['content']
                        full_content += chunk_content
                        full_content += "\n\n"
                        
                        # ê° ì²­í¬ ì •ë³´ë¥¼ citationsì— ì €ì¥ (chunk í‚¤ë¡œ)
                        # citationsëŠ” ë‚˜ì¤‘ì— final_agentì—ì„œ ì¶”ì¶œë¨
                        chunk_info = {
                            "id": chunk.get('id'),
                            "content": chunk_content,
                            "title": title,
                            "source": doc.get('source', ''),
                            "file_url": file_url,
                            "metadata": chunk.get('metadata', {})
                        }
                        citations.append({
                            "chunk": chunk_info,
                            "source": title,  # ê¸°ì¡´ í˜•ì‹ ìœ ì§€
                            "url": file_url
                        })

            # ============================================================
            # 4ë‹¨ê³„: ì •ë³´ ì¶”ì¶œ
            # ============================================================
            _log("")
            _log(f"ğŸ“‹ [4ë‹¨ê³„] ì •ë³´ ì¶”ì¶œ")

            # ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œì²˜ ëª©ë¡ ìƒì„±
            sources_list = "\n".join([f"- {s}" for s in sources])

            extract_prompt = f"""ë‹¤ìŒ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° í•„ìš”í•œ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œì²˜ ëª©ë¡:
{sources_list}

ë¬¸ì„œ ë‚´ìš©:
{full_content[:15000]}

ì¶œë ¥ ê·œì¹™:
1. í•µì‹¬ ì •ë³´ë§Œ ê°„ê²°í•˜ê²Œ ì¶”ì¶œ
2. ìˆ˜ì¹˜ ë°ì´í„°ëŠ” ì •í™•í•˜ê²Œ ìœ ì§€
3. ê° ì •ë³´ê°€ ì–´ëŠ ë¬¸ì„œì—ì„œ ì™”ëŠ”ì§€ [ì¶œì²˜: ë¬¸ì„œëª…] í˜•ì‹ìœ¼ë¡œ ë°˜ë“œì‹œ í‘œì‹œ
4. ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ë‹¤ë©´, ê° ì •ë³´ë§ˆë‹¤ í•´ë‹¹ ì¶œì²˜ë¥¼ í‘œì‹œ
5. ë§ˆì§€ë§‰ì— "ì¶œì²˜: ë¬¸ì„œ1, ë¬¸ì„œ2, ..." í˜•íƒœë¡œ ìš”ì•½í•˜ì§€ ë§ê³ , ì •ë³´ë§ˆë‹¤ ê°œë³„ í‘œì‹œ
6. JSONì´ ì•„ë‹Œ ìì—°ì–´ë¡œ ì‘ì„±"""

            try:
                extracted_info = await gemini_service.generate(
                    extract_prompt,
                    "ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ ì „ë¬¸ê°€"
                )

                # citationsëŠ” ì´ë¯¸ ì²­í¬ ì •ë³´ì™€ í•¨ê»˜ ì¶”ê°€ë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì‘ì—… ë¶ˆí•„ìš”

            except Exception as e:
                extracted_info = f"ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}"
            
            _log(f"   ì¶”ì¶œëœ ì •ë³´ ê¸¸ì´: {len(extracted_info)}ì")
            _log("="*60)

            return {
                "agent": self.name,
                "status": "success",
                "query": query,
                "result": extracted_info,
                "sources": sources,
                "source_urls": source_urls,
                "citations": citations
            }

        except Exception as e:
            _log(f"âŒ {self.name} ì˜¤ë¥˜: {e}")
            return {
                "agent": self.name,
                "status": "error",
                "result": str(e),
                "sources": [],
                "source_urls": [],
                "citations": []
            }


class ConsultingAgent(SubAgentBase):
    """
    ì»¨ì„¤íŒ… Agent - ì„ì‹œ DBì—ì„œ ì…ê²°/í™˜ì‚°ì ìˆ˜ ë°ì´í„° ì¡°íšŒ
    5ê°œ ëŒ€í•™(ì„œìš¸ëŒ€/ì—°ì„¸ëŒ€/ê³ ë ¤ëŒ€/ì„±ê· ê´€ëŒ€/ê²½í¬ëŒ€) ë°ì´í„° ì‚¬ìš©
    """

    def __init__(self, custom_system_prompt: str = None):
        super().__init__(
            name="ì»¨ì„¤íŒ… agent",
            description="5ê°œ ëŒ€í•™ í•©ê²© ë°ì´í„° ë¹„êµ ë¶„ì„, í•©ê²© ê°€ëŠ¥ì„± í‰ê°€",
            custom_system_prompt=custom_system_prompt
        )

    async def execute(self, query: str) -> Dict[str, Any]:
        """ì„±ì  ê¸°ë°˜ í•©ê²© ê°€ëŠ¥ ëŒ€í•™ ë¶„ì„"""
        _log("")
        _log("="*60)
        _log(f"ğŸ“Š ì»¨ì„¤íŒ… Agent ì‹¤í–‰")
        _log("="*60)
        _log(f"ì¿¼ë¦¬: {query}")

        # ì¿¼ë¦¬ì—ì„œ ì„±ì  ì •ë³´ ì¶”ì¶œ
        grade_info = self._extract_grade_from_query(query)
        _log(f"   ì¶”ì¶œëœ ì„±ì : {grade_info}")

        # DBì—ì„œ ë°ì´í„° ì¡°íšŒ
        susi_data = None
        jeongsi_data = None

        if grade_info.get("ë‚´ì‹ "):
            susi_data = get_admission_data_by_grade(grade_info["ë‚´ì‹ "])

        if grade_info.get("ë°±ë¶„ìœ„"):
            jeongsi_data = get_jeongsi_data_by_percentile(grade_info["ë°±ë¶„ìœ„"])

        # ì „ì²´ ë°ì´í„° í¬í•¨
        all_data = get_all_universities_data()
        all_data["í•™ìƒ_ì„±ì ë¶„ì„"] = {
            "ìˆ˜ì‹œ": susi_data,
            "ì •ì‹œ": jeongsi_data
        } if (susi_data or jeongsi_data) else None

        # Geminië¡œ ë¶„ì„
        if self.custom_system_prompt:
            system_prompt = self.custom_system_prompt.format(
                all_data=json.dumps(all_data, ensure_ascii=False, indent=2)[:8000]
            )
            print(f"ğŸ¨ Using custom system prompt for consulting agent")
        else:
            system_prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•™ ì…ì‹œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ í•„ìš”í•œ íŒ©íŠ¸ì™€ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ì œê³µí•˜ì„¸ìš”.

## ê°€ìš© ë°ì´í„°
{json.dumps(all_data, ensure_ascii=False, indent=2)[:8000]}

## ì¶œë ¥ ê·œì¹™ (í•„ìˆ˜)
1. ì§ˆë¬¸ì— í•„ìš”í•œ í•µì‹¬ ë°ì´í„°ë§Œ ê°„ê²°í•˜ê²Œ ì œì‹œ
2. ìˆ˜ì¹˜ ë°ì´í„°ëŠ” ì •í™•í•˜ê²Œ í‘œê¸°
3. ê° ì •ë³´ ë’¤ì— [ì¶œì²˜: ì»¨ì„¤íŒ…DB] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ í‘œì‹œ
4. JSONì´ ì•„ë‹Œ ìì—°ì–´ë¡œ ì¶œë ¥
5. ê²©ë ¤ë‚˜ ì¡°ì–¸ì€ í•˜ì§€ ë§ê³  ì˜¤ì§ ë°ì´í„°ë§Œ ì œê³µ
6. "í•©ê²©ê°€ëŠ¥", "ë„ì „ê°€ëŠ¥" ê°™ì€ íŒë‹¨ì€ í•˜ì§€ ë§ê³  ì‚¬ì‹¤ë§Œ ë‚˜ì—´
7. ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(**, *, #, ##, ###) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
8. ê¸€ë¨¸ë¦¬ ê¸°í˜¸ëŠ” - ë˜ëŠ” â€¢ ë§Œ ì‚¬ìš©

ì˜ˆì‹œ:
- 2024í•™ë…„ë„ ì„œìš¸ëŒ€ ê¸°ê³„ê³µí•™ë¶€ ìˆ˜ì‹œ ì¼ë°˜ì „í˜• 70% ì»¤íŠ¸ë¼ì¸: ë‚´ì‹  1.5ë“±ê¸‰ [ì¶œì²˜: ì»¨ì„¤íŒ…DB]
- 2024í•™ë…„ë„ ì—°ì„¸ëŒ€ ê¸°ê³„ê³µí•™ë¶€ ì •ì‹œ 70% ì»¤íŠ¸ë¼ì¸: ë°±ë¶„ìœ„ 95.2 [ì¶œì²˜: ì»¨ì„¤íŒ…DB]"""

        try:
            response = self.model.generate_content(
                f"{system_prompt}\n\nì§ˆë¬¸: {query}\n\nìœ„ ë°ì´í„°ì—ì„œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ”ë° í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.",
                generation_config={"temperature": 0.1, "max_output_tokens": 1024},
                request_options=genai.types.RequestOptions(
                    retry=None,
                    timeout=120.0  # ë©€í‹°ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ì„ ìœ„í•´ 120ì´ˆë¡œ ì¦ê°€
                )
            )

            # í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
            if hasattr(response, 'usage_metadata'):
                usage = response.usage_metadata
                print(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰ ({self.name}): {usage}")
                
                log_token_usage(
                    operation="ì…ê²°ë¹„êµì—ì´ì „íŠ¸",
                    prompt_tokens=getattr(usage, 'prompt_token_count', 0),
                    output_tokens=getattr(usage, 'candidates_token_count', 0),
                    total_tokens=getattr(usage, 'total_token_count', 0),
                    model="gemini-3-flash-preview",
                    details=self.name
                )

            result_text = response.text
            
            # citations êµ¬ì„±
            citations = [{
                "text": "5ê°œ ëŒ€í•™ ì…ê²° ë°ì´í„° ë¶„ì„",
                "source": "ì»¨ì„¤íŒ… DB (ì„œìš¸ëŒ€/ì—°ì„¸ëŒ€/ê³ ë ¤ëŒ€/ì„±ê· ê´€ëŒ€/ê²½í¬ëŒ€)",
                "url": ""
            }]

            _log(f"   ë¶„ì„ ì™„ë£Œ")
            _log("="*60)

            return {
                "agent": self.name,
                "status": "success",
                "query": query,
                "result": result_text,
                "grade_info": grade_info,
                "sources": ["ì»¨ì„¤íŒ… DB"],
                "source_urls": [],
                "citations": citations
            }

        except Exception as e:
            return {
                "agent": self.name,
                "status": "error",
                "result": str(e),
                "sources": [],
                "source_urls": [],
                "citations": []
            }

    def _extract_grade_from_query(self, query: str) -> Dict[str, float]:
        """ì¿¼ë¦¬ì—ì„œ ì„±ì  ì •ë³´ ì¶”ì¶œ"""
        result = {}

        # ë‚´ì‹  ë“±ê¸‰ ì¶”ì¶œ
        grade_pattern = r'(\d+\.?\d*)\s*ë“±ê¸‰|ë‚´ì‹ \s*(\d+\.?\d*)'
        match = re.search(grade_pattern, query)
        if match:
            grade = match.group(1) or match.group(2)
            result["ë‚´ì‹ "] = float(grade)

        # ë°±ë¶„ìœ„ ì¶”ì¶œ
        pct_pattern = r'ë°±ë¶„ìœ„\s*(\d+\.?\d*)|(\d+\.?\d*)\s*%'
        match = re.search(pct_pattern, query)
        if match:
            pct = match.group(1) or match.group(2)
            result["ë°±ë¶„ìœ„"] = float(pct)

        return result


class TeacherAgent(SubAgentBase):
    """ì„ ìƒë‹˜ Agent - í•™ìŠµ ê³„íš ë° ë©˜íƒˆ ê´€ë¦¬ ì¡°ì–¸"""

    def __init__(self, custom_system_prompt: str = None):
        super().__init__(
            name="ì„ ìƒë‹˜ agent",
            description="í˜„ì‹¤ì ì¸ ëª©í‘œ ì„¤ì • ë° ê³µë¶€ ê³„íš ìˆ˜ë¦½, ë©˜íƒˆ ê´€ë¦¬",
            custom_system_prompt=custom_system_prompt
        )

    async def execute(self, query: str) -> Dict[str, Any]:
        """í•™ìŠµ ê³„íš ë° ì¡°ì–¸ ì œê³µ"""
        _log("")
        _log("="*60)
        _log(f"ğŸ‘¨â€ğŸ« ì„ ìƒë‹˜ Agent ì‹¤í–‰")
        _log("="*60)
        _log(f"ì¿¼ë¦¬: {query}")

        if self.custom_system_prompt:
            system_prompt = self.custom_system_prompt
            print(f"ğŸ¨ Using custom system prompt for teacher agent")
        else:
            system_prompt = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ì…ì‹œ ì „ë¬¸ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
í•™ìƒì˜ ìƒí™©ì„ íŒŒì•…í•˜ê³  í˜„ì‹¤ì ì´ë©´ì„œë„ í¬ë§ì„ ìƒì§€ ì•ŠëŠ” ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.

## ì¡°ì–¸ ì›ì¹™
1. í˜„ì‹¤ì ì¸ ëª©í‘œ ì„¤ì • (ë¬´ë¦¬í•œ ëª©í‘œëŠ” ì§€ì )
2. êµ¬ì²´ì ì¸ ì‹œê°„í‘œì™€ ê³„íš ì œì‹œ
3. ë©˜íƒˆ ê´€ë¦¬ ì¡°ì–¸ í¬í•¨
4. ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ëª©í‘œ êµ¬ë¶„
5. í¬ê¸°í•˜ì§€ ì•Šë„ë¡ ê²©ë ¤í•˜ë˜, ê±°ì§“ í¬ë§ì€ ì£¼ì§€ ì•Šê¸°

## ì¶œë ¥ í˜•ì‹
- ìì—°ì–´ë¡œ ì¹œê·¼í•˜ê²Œ ì‘ì„±
- í•„ìš”ì‹œ ë¦¬ìŠ¤íŠ¸ë‚˜ í‘œ ì‚¬ìš©
- ì¡´ëŒ“ë§ ì‚¬ìš©"""

        try:
            response = self.model.generate_content(
                f"{system_prompt}\n\ní•™ìƒ ì§ˆë¬¸: {query}\n\nì„ ìƒë‹˜ìœ¼ë¡œì„œ ì¡°ì–¸í•´ì£¼ì„¸ìš”.",
                generation_config={"temperature": 0.7},
                request_options=genai.types.RequestOptions(
                    retry=None,
                    timeout=120.0  # ë©€í‹°ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ì„ ìœ„í•´ 120ì´ˆë¡œ ì¦ê°€
                )
            )

            # í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
            if hasattr(response, 'usage_metadata'):
                usage = response.usage_metadata
                print(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰ ({self.name}): {usage}")
                
                log_token_usage(
                    operation="ì„ ìƒë‹˜ì—ì´ì „íŠ¸",
                    prompt_tokens=getattr(usage, 'prompt_token_count', 0),
                    output_tokens=getattr(usage, 'candidates_token_count', 0),
                    total_tokens=getattr(usage, 'total_token_count', 0),
                    model="gemini-3-flash-preview",
                    details=self.name
                )

            _log(f"   ì¡°ì–¸ ì™„ë£Œ")
            _log("="*60)

            return {
                "agent": self.name,
                "status": "success",
                "query": query,
                "result": response.text,
                "sources": [],
                "source_urls": [],
                "citations": []
            }

        except Exception as e:
            return {
                "agent": self.name,
                "status": "error",
                "result": str(e),
                "sources": [],
                "source_urls": [],
                "citations": []
            }


# ============================================================
# Agent Factory
# ============================================================

def get_agent(agent_name: str) -> SubAgentBase:
    """ì—ì´ì „íŠ¸ ì´ë¦„ìœ¼ë¡œ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    agent_name_lower = agent_name.lower()

    # ëŒ€í•™ë³„ Agent
    for univ in UniversityAgent.SUPPORTED_UNIVERSITIES:
        if univ in agent_name:
            return UniversityAgent(univ)

    # ì»¨ì„¤íŒ… Agent
    if "ì»¨ì„¤íŒ…" in agent_name or "ì»¨ì„¤í„´íŠ¸" in agent_name:
        return ConsultingAgent()

    # ì„ ìƒë‹˜ Agent
    if "ì„ ìƒë‹˜" in agent_name or "ì„ ìƒ" in agent_name:
        return TeacherAgent()

    raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—ì´ì „íŠ¸: {agent_name}")


async def execute_sub_agents(execution_plan: list) -> Dict[str, Any]:
    """
    Execution Planì— ë”°ë¼ Sub Agentë“¤ ì‹¤í–‰
    
    Args:
        execution_plan: Orchestration Agentê°€ ìƒì„±í•œ ì‹¤í–‰ ê³„íš
        
    Returns:
        {
            "Step1_Result": {...},
            "Step2_Result": {...},
            ...
        }
    """
    results = {}

    for step in execution_plan:
        step_num = step.get("step")
        agent_name = step.get("agent")
        query = step.get("query")

        _log(f"   Step {step_num}: {agent_name}")
        _log(f"   Query: {query}")

        try:
            agent = get_agent(agent_name)
            result = await agent.execute(query)
            results[f"Step{step_num}_Result"] = result
            
            status_icon = "âœ…" if result.get('status') == 'success' else "âŒ"
            _log(f"   {status_icon} Status: {result.get('status')}")
            sources_count = len(result.get('sources', []))
            if sources_count > 0:
                _log(f"   ì¶œì²˜: {sources_count}ê°œ")
            
        except Exception as e:
            _log(f"   âŒ Error: {e}")
            results[f"Step{step_num}_Result"] = {
                "agent": agent_name,
                "status": "error",
                "result": str(e),
                "sources": [],
                "source_urls": [],
                "citations": []
            }

    return results
