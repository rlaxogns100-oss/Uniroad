"""
ì„ë² ë”© ê¸°ë°˜ PDF ì²˜ë¦¬ ì„œë¹„ìŠ¤
Streamlit ì—†ì´ core/pdf íŒŒì´í”„ë¼ì¸ì„ í˜¸ì¶œ
"""
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Callable, Dict, Optional, Tuple, Union

from core.pdf import TOCProcessor, SectionPreprocessor
from config import embedding_settings as config
from services.supabase_client import SupabaseUploader


def process_pdf(
    pdf_path: str,
    school_name: str,
    on_progress: Optional[Callable[[str, str], None]] = None,
    strict_mode: bool = True
) -> Union[Dict, Tuple[None, str]]:
    """
    PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ processed_data ë”•ì…”ë„ˆë¦¬ë¥¼ ìƒì„±.
    ì„±ê³µ ì‹œ Dict, ì‹¤íŒ¨ ì‹œ (None, ì‹¤íŒ¨_ì‚¬ìœ _ë¬¸ìì—´) ë°˜í™˜.
    """

    def log(status: str, message: str = None):
        if on_progress:
            on_progress(status, message or status)

    try:
        log("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...", "ğŸ“¦ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")

        model_name = config.DEFAULT_LLM_MODEL
        toc_processor = TOCProcessor(model_name)
        preprocessor = SectionPreprocessor(model_name)

        log("ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘...", "âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        log("ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘...", "ğŸ“ [0ë‹¨ê³„] ë¬¸ì„œ ìš”ì•½ ìƒì„± ì¤‘...")

        document_summary = toc_processor.generate_document_summary(pdf_path)

        if not document_summary:
            log("ë¬¸ì„œ ìš”ì•½ ìƒì„± ì‹¤íŒ¨", "âš ï¸ ë¬¸ì„œ ìš”ì•½ ìƒì„± ì‹¤íŒ¨. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        else:
            log("ë¬¸ì„œ ìš”ì•½ ìƒì„± ì™„ë£Œ", f"âœ… ë¬¸ì„œ ìš”ì•½ ìƒì„± ì™„ë£Œ ({len(document_summary)}ì)")

        log("ëª©ì°¨ í˜ì´ì§€ ê°ì§€ ì¤‘...", "ğŸ” [1ë‹¨ê³„] ëª©ì°¨ í˜ì´ì§€ ê°ì§€ ì¤‘...")

        toc_pages = toc_processor.detect_toc_pages(pdf_path)
        sections = None

        if not toc_pages:
            log("ëª©ì°¨ í˜ì´ì§€ ì—†ìŒ", "âš ï¸ ëª©ì°¨ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if document_summary:
                log("ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì¤‘...", "ğŸ“‹ ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì‹œë„ ì¤‘...")
                sections = toc_processor.generate_toc_from_summary(pdf_path, document_summary)
                if sections:
                    log("ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì™„ë£Œ", f"âœ… ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì™„ë£Œ: {len(sections)}ê°œ ì„¹ì…˜")
                else:
                    log("ì‹¤íŒ¨: ëª©ì°¨ ìƒì„± ë¶ˆê°€", "âš ï¸ ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì‹¤íŒ¨")
                    return (None, "ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì‹¤íŒ¨")
            else:
                log("ì‹¤íŒ¨: ëª©ì°¨ ìƒì„± ë¶ˆê°€", "âš ï¸ ìš”ì•½ë³¸ë„ ì—†ì–´ ëª©ì°¨ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return (None, "ìš”ì•½ë³¸ì´ ì—†ì–´ ëª©ì°¨ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            log("ëª©ì°¨ í˜ì´ì§€ ë°œê²¬", f"âœ… ëª©ì°¨ í˜ì´ì§€ ë°œê²¬: {[p+1 for p in toc_pages]}")

            log("ëª©ì°¨ êµ¬ì¡° íŒŒì‹± ì¤‘...", "ğŸ“‹ [2ë‹¨ê³„] ëª©ì°¨ êµ¬ì¡° íŒŒì‹± ì¤‘...")
            sections = toc_processor.parse_toc_structure(pdf_path, toc_pages)

            if not sections:
                log("ëª©ì°¨ íŒŒì‹± ì‹¤íŒ¨", "âš ï¸ ëª©ì°¨ íŒŒì‹± ì‹¤íŒ¨.")
                if document_summary:
                    log("ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì¤‘...", "ğŸ“‹ ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì‹œë„ ì¤‘...")
                    sections = toc_processor.generate_toc_from_summary(pdf_path, document_summary)
                    if sections:
                        log("ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì™„ë£Œ", f"âœ… ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì™„ë£Œ: {len(sections)}ê°œ ì„¹ì…˜")
                    else:
                        log("ì‹¤íŒ¨: ëª©ì°¨ ìƒì„± ë¶ˆê°€", "âš ï¸ ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì‹¤íŒ¨")
                        return (None, "ìš”ì•½ ê¸°ë°˜ ëª©ì°¨ ìƒì„± ì‹¤íŒ¨")
                else:
                    log("ì‹¤íŒ¨: ëª©ì°¨ ìƒì„± ë¶ˆê°€", "âš ï¸ ìš”ì•½ë³¸ë„ ì—†ì–´ ëª©ì°¨ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return (None, "ìš”ì•½ë³¸ì´ ì—†ì–´ ëª©ì°¨ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        log("í˜ì´ì§€ ë²”ìœ„ ê²€ì¦ ì¤‘...", "âœ… [3ë‹¨ê³„] í˜ì´ì§€ ë²”ìœ„ ê²€ì¦ ì¤‘...")
        sections = toc_processor.validate_and_fix_sections(sections, pdf_path)
        log("ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ", f"âœ… {len(sections)}ê°œ ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ")

        log(f"ì„¹ì…˜ ì „ì²˜ë¦¬ ì¤‘... (0/{len(sections)})", f"ğŸ“„ [4ë‹¨ê³„] {len(sections)}ê°œ ì„¹ì…˜ ë³‘ë ¬ ì „ì²˜ë¦¬ ì¤‘...")

        section_data = {}
        all_chunks = []
        completed = 0
        total = len(sections)
        failed_sections = []

        def process_section(section):
            section_key = f"{section['start_page']}_{section['end_page']}"
            try:
                result = preprocessor.preprocess_section(section, pdf_path)
                return {
                    "section_key": section_key,
                    "result": result,
                    "section": section,
                    "error": None
                }
            except Exception as e:
                return {
                    "section_key": section_key,
                    "result": None,
                    "section": section,
                    "error": str(e)
                }

        with ThreadPoolExecutor(max_workers=config.MAX_WORKERS) as executor:
            future_to_section = {
                executor.submit(process_section, section): idx
                for idx, section in enumerate(sections, 1)
            }

            for future in as_completed(future_to_section):
                idx = future_to_section[future]
                try:
                    data = future.result()

                    if data.get("error"):
                        error_msg = data.get("error")
                        log(f"ì„¹ì…˜ ì „ì²˜ë¦¬ ì¤‘... ({completed}/{total})", f"âŒ ì„¹ì…˜ {idx} ì˜¤ë¥˜: {error_msg}")
                        failed_sections.append({"idx": idx, "error": error_msg, "section": data.get("section")})
                        completed += 1
                        continue

                    if not data or not data.get("result"):
                        log(f"ì„¹ì…˜ ì „ì²˜ë¦¬ ì¤‘... ({completed}/{total})", f"âŒ ì„¹ì…˜ {idx} ì²˜ë¦¬ ê²°ê³¼ ì—†ìŒ")
                        failed_sections.append({"idx": idx, "error": "ê²°ê³¼ ì—†ìŒ", "section": data.get("section") if data else None})
                        completed += 1
                        continue

                    section_key = data.get("section_key", f"section_{idx}")
                    result = data.get("result", {})
                    section = data.get("section", {"title": f"ì„¹ì…˜ {idx}"})

                    documents = result.get("documents", [])
                    if not documents:
                        log(f"ì„¹ì…˜ ì „ì²˜ë¦¬ ì¤‘... ({completed}/{total})", f"âš ï¸ ì„¹ì…˜ {idx} ì²­í¬ ì—†ìŒ (ê±´ë„ˆëœ€)")
                        completed += 1
                        continue

                    section_data[section_key] = {
                        "vectorstore": result.get("vectorstore"),
                        "documents": documents,
                        "section": section,
                        "table_count": result.get("table_count", 0)
                    }

                    all_chunks.extend(documents)

                    completed += 1
                    table_count = result.get("table_count", 0)
                    table_info = f" (í‘œ {table_count}ê°œ)" if table_count > 0 else ""
                    section_title = section.get("title", f"ì„¹ì…˜ {idx}")
                    log(f"ì„¹ì…˜ ì „ì²˜ë¦¬ ì¤‘... ({completed}/{total})",
                        f"âœ… {completed}/{total} ì™„ë£Œ: '{section_title}'{table_info} ({len(documents)}ê°œ ì²­í¬)")
                except Exception as e:
                    log(f"ì„¹ì…˜ ì „ì²˜ë¦¬ ì¤‘... ({completed}/{total})", f"âŒ ì„¹ì…˜ {idx} ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                    failed_sections.append({"idx": idx, "error": str(e), "section": None})
                    completed += 1

        if strict_mode and failed_sections:
            failed_count = len(failed_sections)
            log("ì‹¤íŒ¨: ì²­í¬ ì˜¤ë¥˜ ë°œìƒ", f"âŒ {failed_count}ê°œ ì„¹ì…˜ì—ì„œ ì˜¤ë¥˜ ë°œìƒ - íŒŒì¼ ì „ì²´ ê±´ë„ˆëœ€")
            for fail in failed_sections:
                section_info = fail.get("section", {})
                section_title = section_info.get("title", f"ì„¹ì…˜ {fail['idx']}") if section_info else f"ì„¹ì…˜ {fail['idx']}"
                log("ì‹¤íŒ¨: ì²­í¬ ì˜¤ë¥˜ ë°œìƒ", f"   - {section_title}: {fail['error']}")
            first_err = failed_sections[0].get("error", "ì•Œ ìˆ˜ ì—†ìŒ") if failed_sections else "ì•Œ ìˆ˜ ì—†ìŒ"
            return (None, f"ì„¹ì…˜ ì „ì²˜ë¦¬ ì‹¤íŒ¨ ({failed_count}ê°œ): {first_err}")

        if not all_chunks:
            log("ì‹¤íŒ¨: ì²­í¬ ì—†ìŒ", "âŒ ì²˜ë¦¬ëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return (None, "ì²˜ë¦¬ëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

        log("ì „ì²˜ë¦¬ ì™„ë£Œ", f"ğŸ‰ ëª¨ë“  ì„¹ì…˜ ì „ì²˜ë¦¬ ì™„ë£Œ! ({len(sections)}ê°œ ì„¹ì…˜, ì´ {len(all_chunks)}ê°œ ì²­í¬)")

        if failed_sections and not strict_mode:
            log("ì „ì²˜ë¦¬ ì™„ë£Œ", f"âš ï¸ {len(failed_sections)}ê°œ ì„¹ì…˜ì€ ê±´ë„ˆëœ€")

        return {
            "toc_sections": sections,
            "chunks": all_chunks,
            "summary": document_summary,
            "failed_sections": failed_sections if failed_sections else None
        }
    except Exception as e:
        import traceback
        tb = traceback.format_exc()
        reason = str(e) if str(e) else type(e).__name__
        log(f"ì‹¤íŒ¨: {reason}", f"âŒ ì˜¤ë¥˜ ë°œìƒ: {reason}\n{tb}")
        print(f"\nâŒ [process_pdf] ì˜¤ë¥˜: {e}\n{tb}\n")
        return (None, reason)


def upload_to_supabase_with_file(
    school_name: str,
    file_path: str,
    processed_data: Dict,
    original_filename: str = None,
    on_progress: Optional[Callable[[str, str], None]] = None
) -> Optional[int]:
    """
    Supabaseì— PDF ë° ì²˜ë¦¬ëœ ë°ì´í„° ì—…ë¡œë“œ
    """

    def log(status: str, message: str = None):
        if on_progress:
            on_progress(status, message or status)

    try:
        log("Supabase ì—…ë¡œë“œ ì¤‘...", "ğŸ“¤ [5ë‹¨ê³„] Supabaseì— ë°ì´í„° ì—…ë¡œë“œ ì¤‘...")
        log("Supabase ì—…ë¡œë“œ ì¤‘...", f"   ì„¹ì…˜ ìˆ˜: {len(processed_data['toc_sections'])}ê°œ")
        log("Supabase ì—…ë¡œë“œ ì¤‘...", f"   ì²­í¬ ìˆ˜: {len(processed_data['chunks'])}ê°œ")

        uploader = SupabaseUploader()
        document_id = uploader.upload_to_supabase(
            school_name=school_name,
            file_path=file_path,
            processed_data=processed_data,
            original_filename=original_filename
        )

        if document_id:
            log("ì—…ë¡œë“œ ì™„ë£Œ", f"   ğŸ‰ ì—…ë¡œë“œ ì™„ë£Œ! ë¬¸ì„œ ID: {document_id}")
            return document_id
        log("ì—…ë¡œë“œ ì‹¤íŒ¨", "   âŒ ì—…ë¡œë“œ ì‹¤íŒ¨")
        return None
    except Exception as e:
        log(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}", f"âŒ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
