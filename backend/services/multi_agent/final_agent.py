"""
Final Agent
- Answer Structure(ì„¤ê³„ë„)ì— ë”°ë¼ Sub Agent ê²°ê³¼(ì¬ë£Œ)ë¥¼ ì¡°ë¦½í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
- ì¶œì²˜ê°€ ìˆëŠ” ì •ë³´ëŠ” <cite> íƒœê·¸ë¡œ ê°ì‹¸ì„œ í‘œì‹œ
- ë³¼ë“œ íƒ€ì´í‹€ì€ ã€ã€‘ ê¸°í˜¸ë¡œ í‘œì‹œ
"""

import google.generativeai as genai
from typing import Dict, Any, List
import os
import re
from dotenv import load_dotenv
from .agent_prompts import get_final_agent_prompt
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))
from token_logger import log_token_usage

load_dotenv()

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ë¡œê·¸ ì½œë°± (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìš©)
_log_callback = None

def set_log_callback(callback):
    """ë¡œê·¸ ì½œë°± ì„¤ì •"""
    global _log_callback
    _log_callback = callback

def _log(msg: str):
    """ë¡œê·¸ ì¶œë ¥ ë° ì½œë°± í˜¸ì¶œ"""
    if _log_callback:
        _log_callback(msg)
    else:
        print(msg)


class FinalAgent:
    """Final Agent - ìµœì¢… ë‹µë³€ ì¡°ë¦½"""

    def __init__(self):
        self.name = "Final Agent"
        self.model = genai.GenerativeModel(
            model_name="gemini-3-flash-preview",
        )

    def _post_process_sections(self, text: str) -> str:
        """
        ì„¹ì…˜ ë§ˆì»¤ë¥¼ ì œê±°í•˜ê³  ê° ì„¹ì…˜ ëì— cite íƒœê·¸ë¥¼ ì •ë¦¬
        
        ë™ì‘:
        1. ===SECTION_START===...===SECTION_END=== íŒ¨í„´ì„ ì°¾ìŒ
        2. ê° ì„¹ì…˜ ë‚´ì˜ ëª¨ë“  cite íƒœê·¸ì—ì„œ data-source, data-url ìˆ˜ì§‘
        3. ì„¹ì…˜ ëì— ìˆ˜ì§‘í•œ cite íƒœê·¸ë“¤ì„ ë¹ˆ íƒœê·¸ë¡œ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        4. ì„¹ì…˜ ë§ˆì»¤ ì œê±°í•˜ê³  ì„¹ì…˜ë“¤ì„ ì„¸ ì¤„ ë°”ê¿ˆìœ¼ë¡œ ì—°ê²° (ì¶œì²˜ í¬í•¨ ì„¹ì…˜ ê°„ ì—¬ë°±)
        """
        # ë¡œê·¸ ì¶”ê°€
        _log("   [í›„ì²˜ë¦¬] ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´: " + str(len(text)))
        _log("   [í›„ì²˜ë¦¬] SECTION_START ê°œìˆ˜: " + str(text.count("===SECTION_START===")))
        
        # ì„¹ì…˜ íŒ¨í„´ ì°¾ê¸°
        section_pattern = r'===SECTION_START===(.*?)===SECTION_END==='
        
        sections = []
        for match in re.finditer(section_pattern, text, flags=re.DOTALL):
            section_content = match.group(1).strip()
            
            # ë¹ˆ ì„¹ì…˜ ìŠ¤í‚µ
            if not section_content:
                _log(f"   [í›„ì²˜ë¦¬] ë¹ˆ ì„¹ì…˜ ë°œê²¬, ìŠ¤í‚µ")
                continue
            
            # cite íƒœê·¸ ì°¾ê¸° (data-urlì€ ì„ íƒì )
            cite_pattern = r'<cite\s+data-source="([^"]*)"(?:\s+data-url="([^"]*)")?\s*>.*?</cite>'
            
            citations = []
            seen = set()
            
            for cite_match in re.finditer(cite_pattern, section_content, flags=re.DOTALL):
                source = cite_match.group(1)
                url = cite_match.group(2) or ""  # data-urlì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
                key = (source, url)
                
                if key not in seen and source:  # ì¤‘ë³µ ì œê±° ë° ë¹ˆ source ì œì™¸
                    seen.add(key)
                    citations.append((source, url))
            
            # ë³¸ë¬¸ì—ì„œ cite íƒœê·¸ ëª¨ë‘ ì œê±°
            section_content_clean = re.sub(cite_pattern, '', section_content, flags=re.DOTALL)
            section_content_clean = section_content_clean.strip()
            
            # ì„¹ì…˜ ëì— cite íƒœê·¸ ì¶”ê°€
            if citations:
                cite_tags = '\n'.join([
                    f'<cite data-source="{source}" data-url="{url}"></cite>'
                    for source, url in citations
                ])
                final_section = section_content_clean + '\n' + cite_tags
            else:
                final_section = section_content_clean
            
            # ìµœì¢… í™•ì¸: ë¹ˆ ì„¹ì…˜ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¶”ê°€
            if final_section.strip():
                sections.append(final_section)
                _log(f"   [í›„ì²˜ë¦¬] ì„¹ì…˜ #{len(sections)} ì¶”ê°€ (ê¸¸ì´: {len(final_section)}ì)")
        
        # ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
        if not sections:
            _log("   [í›„ì²˜ë¦¬] âš ï¸ ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•¨, ì›ë³¸ ë°˜í™˜")
            return text.strip()
        
        # ì„¹ì…˜ ê°„ ì„¸ ì¤„ ê°„ê²©ìœ¼ë¡œ ì—°ê²° (ì¶œì²˜ í¬í•¨ ì„¹ì…˜ ì•„ë˜ ë¹ˆ ì¤„ í•˜ë‚˜ ì¶”ê°€)
        result = '\n\n\n'.join(sections)
        
        _log("   [í›„ì²˜ë¦¬] ì²˜ë¦¬ëœ ì„¹ì…˜ ìˆ˜: " + str(len(sections)))
        _log("   [í›„ì²˜ë¦¬] ìµœì¢… í…ìŠ¤íŠ¸ ê¸¸ì´: " + str(len(result)) + "ì")
        
        return result.strip()

    async def generate_final_answer(
        self,
        user_question: str,
        answer_structure: List[Dict],
        sub_agent_results: Dict[str, Any],
        custom_prompt: str = None,
        history: List[Dict] = None
    ) -> Dict[str, Any]:
        """
        Answer Structureì— ë”°ë¼ ìµœì¢… ë‹µë³€ ìƒì„±

        Args:
            user_question: ì›ë˜ ì‚¬ìš©ì ì§ˆë¬¸
            answer_structure: Orchestration Agentê°€ ë§Œë“  ë‹µë³€ êµ¬ì¡°
            sub_agent_results: Sub Agentë“¤ì˜ ì‹¤í–‰ ê²°ê³¼
            custom_prompt: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)
            history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœê·¼ 10ê°œ ëŒ€í™”)

        Returns:
            {
                "status": str,
                "final_answer": str,
                "sources": List[str],
                "source_urls": List[str],
                "metadata": Dict
            }
        """
        _log("")
        _log("="*80)
        _log("ğŸ“ Final Agent ì‹¤í–‰")
        _log("="*80)
        
        # historyë¥¼ user_questionì— ë³‘í•©
        user_question_with_context = self._merge_history_with_question(user_question, history)
        
        # ì…ë ¥ ë°ì´í„° ê²€ì¦ ë¡œê·¸
        _log(f"ğŸ” [ì…ë ¥ ê²€ì¦]")
        _log(f"   user_question: {user_question[:100]}..." if len(user_question) > 100 else f"   user_question: {user_question}")
        _log(f"   history ëŒ€í™” ìˆ˜: {len(history) if history else 0}")
        _log(f"   answer_structure ì„¹ì…˜ ìˆ˜: {len(answer_structure)}")
        _log(f"   sub_agent_results í‚¤: {list(sub_agent_results.keys())}")
        _log(f"   custom_prompt ì‚¬ìš©: {'âœ… Yes' if custom_prompt else 'âŒ No (ê¸°ë³¸ prompt4 ì‚¬ìš©)'}")

        # Sub Agent ê²°ê³¼ ì •ë¦¬ + ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘
        results_text, all_sources, all_source_urls, all_citations = self._format_sub_agent_results(sub_agent_results)

        # Answer Structureë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        structure_text = self._format_answer_structure(answer_structure)

        
        # ğŸ” í…ŒìŠ¤íŠ¸ í™˜ê²½ìš© ë³µì‚¬ ê°€ëŠ¥í•œ ë°ì´í„° ì¶œë ¥
        import json as _json
        _log(f"")
        _log("=" * 80)
        _log("ğŸ“‹ [Final Agent ì…ë ¥ ë°ì´í„° - í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ë³µì‚¬ ê°€ëŠ¥]")
        _log("=" * 80)
        
        # JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (ë³µì‚¬í•´ì„œ í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥)
        test_data = {
            "user_question_with_context": user_question_with_context,
            "structure_text": structure_text,
            "results_text": results_text,
            "all_citations": all_citations
        }
        
        _log(f"\n--- 1. user_question_with_context ---")
        _log(user_question_with_context)
        _log(f"\n--- 2. structure_text ---")
        _log(structure_text)
        _log(f"\n--- 3. results_text ---")
        _log(results_text)
        _log(f"\n--- 4. all_citations (JSON) ---")
        _log(_json.dumps(all_citations, ensure_ascii=False, indent=2))
        _log("=" * 80)

        # í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        if custom_prompt:
            _log(f"ğŸ¨ [ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©] ê¸¸ì´: {len(custom_prompt)}ì")
            prompt = custom_prompt.format(
                user_question=user_question_with_context,
                structure_text=structure_text,
                results_text=results_text,
                all_citations="\n".join([str(c) for c in all_citations])
            )
        else:
            _log(f"ğŸ“‹ [ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: prompt5]")
            prompt = get_final_agent_prompt(
                "prompt5",
                user_question=user_question_with_context,
                structure_text=structure_text,
                results_text=results_text,
                all_citations=all_citations
            )
        
        _log(f"   ìµœì¢… í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}ì")

        try:
            response = self.model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.7,
                    "max_output_tokens": 4096
                },
                request_options=genai.types.RequestOptions(
                    retry=None,
                    timeout=120.0  # ë©€í‹°ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ì„ ìœ„í•´ 120ì´ˆë¡œ ì¦ê°€
                )
            )

            # í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
            if hasattr(response, 'usage_metadata'):
                usage = response.usage_metadata
                print(f"ğŸ’° í† í° ì‚¬ìš©ëŸ‰ (final_agent): {usage}")
                
                log_token_usage(
                    operation="ìµœì¢…ë‹µë³€ìƒì„±",
                    prompt_tokens=getattr(usage, 'prompt_token_count', 0),
                    output_tokens=getattr(usage, 'candidates_token_count', 0),
                    total_tokens=getattr(usage, 'total_token_count', 0),
                    model="gemini-3-flash-preview",
                    details="Final Agent"
                )

            # í›„ì²˜ë¦¬: ì„¹ì…˜ ë§ˆì»¤ ì œê±° ë° cite íƒœê·¸ ì •ë¦¬
            raw_answer = response.text
            final_answer = self._post_process_sections(raw_answer)

            _log(f"   ì›ë³¸ ë‹µë³€ ê¸¸ì´: {len(raw_answer)}ì")
            _log(f"   í›„ì²˜ë¦¬ ë‹µë³€ ê¸¸ì´: {len(final_answer)}ì")
            _log("="*80)

            return {
                "status": "success",
                "final_answer": final_answer,
                "raw_answer": raw_answer,  # âœ… ì›ë³¸ ì¶”ê°€
                "sources": all_sources,
                "source_urls": all_source_urls,
                "metadata": {
                    "sections_count": len(answer_structure),
                    "sub_agents_used": list(sub_agent_results.keys()),
                    "history_count": len(history) if history else 0
                }
            }

        except Exception as e:
            _log(f"âŒ Final Agent ì˜¤ë¥˜: {e}")
            return {
                "status": "error",
                "error": str(e),
                "final_answer": self._generate_fallback_answer(
                    user_question, answer_structure, sub_agent_results
                ),
                "sources": all_sources,
                "source_urls": all_source_urls,
                "metadata": {}
            }

    def _merge_history_with_question(self, user_question: str, history: List[Dict] = None) -> str:
        """
        ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì‚¬ìš©ì ì§ˆë¬¸ì— ë³‘í•©
        
        Args:
            user_question: í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸
            history: ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸ [{role: str, content: str}, ...]
            
        Returns:
            ë§¥ë½ì´ í¬í•¨ëœ ì§ˆë¬¸ ë¬¸ìì—´
        """
        if not history or len(history) == 0:
            return user_question
        
        # ìµœê·¼ 10ê°œ ëŒ€í™”ë¡œ ì œí•œ (20ê°œ ë©”ì‹œì§€ = user + assistant ìŒ)
        recent_history = history[-20:] if len(history) > 20 else history
        
        # íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
        history_lines = []
        for msg in recent_history:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            if role == "user":
                history_lines.append(f"[User] {content}")
            elif role == "assistant":
                # ë‹µë³€ì€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ í‘œì‹œ
                truncated = content[:300] + "..." if len(content) > 300 else content
                history_lines.append(f"[Assistant] {truncated}")
        
        if not history_lines:
            return user_question
        
        _log(f"   ğŸ“œ [ëŒ€í™” ë§¥ë½ ë³‘í•©] {len(recent_history)}ê°œ ë©”ì‹œì§€ í¬í•¨")
        
        return f"""## ì´ì „ ëŒ€í™” ë§¥ë½
{chr(10).join(history_lines)}

## í˜„ì¬ ì§ˆë¬¸
{user_question}"""

    def _format_sub_agent_results(self, results: Dict[str, Any]) -> tuple:
        """
        Sub Agent ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·í•˜ê³  ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘

        Returns:
            (formatted_text, sources, source_urls, citations)
        """
        formatted = []
        all_sources = []
        all_source_urls = []
        all_citations = []

        for step_key, result in results.items():
            agent_name = result.get("agent", "Unknown")
            status = result.get("status", "unknown")
            content = result.get("result", "ê²°ê³¼ ì—†ìŒ")
            sources = result.get("sources", [])
            source_urls = result.get("source_urls", [])
            citations = result.get("citations", [])

            # ì¶œì²˜ ì •ë³´ ìˆ˜ì§‘
            all_sources.extend(sources)
            all_source_urls.extend(source_urls)
            all_citations.extend(citations)

            # ì¶œì²˜ ì •ë³´ë¥¼ ê²°ê³¼ì— í¬í•¨
            source_info = ""
            if sources:
                source_info = f"\n[ì‚¬ìš© ê°€ëŠ¥í•œ ì¶œì²˜: {', '.join(sources)}]"
                if source_urls:
                    for i, (src, url) in enumerate(zip(sources, source_urls)):
                        source_info += f"\n  - {src}: {url}"

            formatted.append(f"""### {step_key} ({agent_name})
ìƒíƒœ: {status}

{content}
{source_info}
""")

        return "\n---\n".join(formatted), all_sources, all_source_urls, all_citations

    def _format_answer_structure(self, structure: List[Dict]) -> str:
        """Answer Structureë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        formatted = []

        for section in structure:
            sec_num = section.get("section", "?")
            sec_type = section.get("type", "unknown")
            title = section.get("title", "")
            source = section.get("source_from", "ì—†ìŒ")
            instruction = section.get("instruction", "")
            
            formatted.append(f"""**ì„¹ì…˜ {sec_num}** [{sec_type}]
- íƒ€ì´í‹€: {title if title else "(íƒ€ì´í‹€ ì—†ìŒ)"}
- ì°¸ì¡°í•  ë°ì´í„°: {source if source else "ì—†ìŒ (ì§ì ‘ ì‘ì„±)"}
- ì§€ì‹œì‚¬í•­: {instruction}""")

        return "\n\n".join(formatted)

    def _generate_fallback_answer(
        self,
        question: str,
        structure: List[Dict],
        results: Dict[str, Any]
    ) -> str:
        """ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ë‹µë³€ ìƒì„±"""
        parts = []

        for section in structure:
            sec_type = section.get("type", "")
            instruction = section.get("instruction", "")
            source = section.get("source_from")

            if sec_type == "empathy":
                parts.append("ì§ˆë¬¸í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì…ì‹œ ì¤€ë¹„ê°€ ì‰½ì§€ ì•Šìœ¼ì‹œì£ .")
            elif source and source in results:
                result = results[source].get("result", "")
                if result:
                    parts.append(result[:500])
            else:
                parts.append(instruction)

        return "\n\n".join(parts) if parts else "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
final_agent = FinalAgent()


async def generate_final_answer(
    user_question: str,
    answer_structure: List[Dict],
    sub_agent_results: Dict[str, Any],
    history: List[Dict] = None
) -> Dict[str, Any]:
    """Final Agentë¥¼ í†µí•´ ìµœì¢… ë‹µë³€ ìƒì„±"""
    return await final_agent.generate_final_answer(
        user_question=user_question,
        answer_structure=answer_structure,
        sub_agent_results=sub_agent_results,
        history=history
    )
