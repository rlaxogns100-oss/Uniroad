"""
Gemini PDF íŒŒì‹± ì„œë¹„ìŠ¤ (5í˜ì´ì§€ì”© ë³‘ë ¬ ì²˜ë¦¬)
ì €ë ´í•˜ê³  ë¹ ë¥¸ PDF â†’ Markdown ë³€í™˜
"""
import google.generativeai as genai
from config import settings
from config.logging_config import setup_logger
import asyncio
from typing import Optional, List
import tempfile
import os
import time
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from utils.token_logger import log_token_usage

logger = setup_logger('gemini_pdf')


class GeminiPDFService:
    """Geminië¥¼ ì‚¬ìš©í•œ PDF íŒŒì‹± (5í˜ì´ì§€ì”© ë³‘ë ¬ ì²˜ë¦¬)"""

    def __init__(self):
        genai.configure(api_key=settings.GEMINI_API_KEY)
        # Lite ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥´ê³  ì €ë ´)
        self.model = genai.GenerativeModel('gemini-2.5-flash-lite')
        logger.info("âœ… GeminiPDFService ì´ˆê¸°í™” ì™„ë£Œ: gemini-2.5-flash-lite")
    
    def _remove_repetitions(self, text: str, min_length: int = 100) -> str:
        """
        ë°˜ë³µë˜ëŠ” íŒ¨í„´ ì œê±° (Gemini hallucination ë°©ì§€)
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            min_length: ìµœì†Œ ë°˜ë³µ ê¸¸ì´
        
        Returns:
            ë°˜ë³µ ì œê±°ëœ í…ìŠ¤íŠ¸
        """
        if len(text) < min_length * 3:
            return text
        
        # ê¸´ ë°˜ë³µ íŒ¨í„´ ì°¾ê¸° (100ì ì´ìƒ)
        import re
        
        # ê°™ì€ ë¬¸ì¥/í‘œê°€ ì—°ì†ìœ¼ë¡œ 3ë²ˆ ì´ìƒ ë°˜ë³µë˜ëŠ” íŒ¨í„´ ì œê±°
        # ì˜ˆ: "AAA" â†’ "A"
        pattern = r'(.{' + str(min_length) + r',}?)(\1{2,})'
        
        original_len = len(text)
        text = re.sub(pattern, r'\1', text, flags=re.DOTALL)
        
        if len(text) < original_len:
            logger.info(f"   ğŸ”§ ë°˜ë³µ íŒ¨í„´ ì œê±°: {original_len:,}ì â†’ {len(text):,}ì")
        
        return text

    async def _parse_pdf_chunk(
        self,
        pdf_bytes: bytes,
        chunk_id: int,
        start_page: int,
        end_page: int
    ) -> tuple:
        """
        PDF ì²­í¬ë¥¼ Geminië¡œ íŒŒì‹± (ë‹¨ì¼ ì²­í¬ ì²˜ë¦¬)

        Args:
            pdf_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
            chunk_id: ì²­í¬ ID (ë¡œê¹…ìš©)
            start_page: ì‹œì‘ í˜ì´ì§€ (1ë¶€í„° ì‹œì‘, í‘œì‹œìš©)
            end_page: ë í˜ì´ì§€

        Returns:
            (chunk_id, markdown_text, usage_metadata)
        """
        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(pdf_bytes)
                tmp_path = tmp_file.name

            try:
                # PDF íŒŒì¼ ì—…ë¡œë“œ
                logger.info(f"   ğŸ“¤ ì²­í¬ {chunk_id} ì—…ë¡œë“œ ì‹œì‘...")
                upload_start = time.time()
                uploaded_file = genai.upload_file(tmp_path)
                upload_time = time.time() - upload_start
                logger.info(f"   âœ… ì²­í¬ {chunk_id} ì—…ë¡œë“œ ì™„ë£Œ ({upload_time:.2f}ì´ˆ)")
                
                # Markdown ë³€í™˜ í”„ë¡¬í”„íŠ¸
                prompt = """ì´ PDF ë¬¸ì„œë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë³€í™˜í•´ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš” ê·œì¹™:
1. ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”
2. í‘œ(table)ëŠ” Markdown í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”
3. ì œëª©, ë¦¬ìŠ¤íŠ¸ ë“± êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”
4. í•œêµ­ì–´ë¥¼ ì •í™•í•˜ê²Œ ì¸ì‹í•˜ì„¸ìš”
5. ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ê³  ë³€í™˜ë§Œ í•˜ì„¸ìš”
6. **ì ˆëŒ€ ê°™ì€ ë‚´ìš©ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”** (í‘œë„ í•œ ë²ˆë§Œ!)
7. **ê° í˜ì´ì§€ ë‚´ìš©ì€ í•œ ë²ˆë§Œ ì¶œë ¥í•˜ì„¸ìš”**

ë³€í™˜ëœ Markdown:"""

                # Geminië¡œ ë³€í™˜ (Retry ë¡œì§ í¬í•¨)
                logger.info(f"   ğŸ¤– ì²­í¬ {chunk_id} Gemini ì²˜ë¦¬ ì‹œì‘...")
                gen_start = time.time()
                
                max_retries = 3
                retry_delays = [2, 4, 8]
                
                for attempt in range(max_retries):
                    try:
                        response = await asyncio.to_thread(
                            self.model.generate_content,
                            [uploaded_file, prompt]
                        )
                        break  # ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
                    except Exception as e:
                        error_msg = str(e)
                        if ("503" in error_msg or "429" in error_msg or "overloaded" in error_msg.lower() or "rate limit" in error_msg.lower()):
                            if attempt < max_retries - 1:
                                delay = retry_delays[attempt]
                                logger.warning(f"   âš ï¸ ì²­í¬ {chunk_id} Rate Limit (ì‹œë„ {attempt + 1}/{max_retries}) â†’ {delay}ì´ˆ í›„ ì¬ì‹œë„")
                                await asyncio.sleep(delay)
                                continue
                            else:
                                logger.error(f"   âŒ ì²­í¬ {chunk_id} ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼")
                                raise
                        else:
                            raise
                
                gen_time = time.time() - gen_start
                logger.info(f"   âœ… ì²­í¬ {chunk_id} Gemini ì²˜ë¦¬ ì™„ë£Œ ({gen_time:.2f}ì´ˆ)")
                
                # í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡
                usage_metadata = None
                if hasattr(response, 'usage_metadata'):
                    usage = response.usage_metadata
                    usage_metadata = {
                        'prompt_tokens': getattr(usage, 'prompt_token_count', 0),
                        'candidates_tokens': getattr(usage, 'candidates_token_count', 0),
                        'total_tokens': getattr(usage, 'total_token_count', 0)
                    }
                    print(f"   ğŸ’° ì²­í¬ {chunk_id} í† í° ì‚¬ìš©ëŸ‰: {usage}")
                    logger.info(f"   ğŸ’° ì²­í¬ {chunk_id} í† í° ì‚¬ìš©ëŸ‰ - "
                              f"ì…ë ¥: {usage_metadata['prompt_tokens']}, "
                              f"ì¶œë ¥: {usage_metadata['candidates_tokens']}, "
                              f"ì´í•©: {usage_metadata['total_tokens']}")
                    
                    # CSVì— ê¸°ë¡
                    log_token_usage(
                        operation="PDFíŒŒì‹±_ì²­í¬",
                        prompt_tokens=usage_metadata['prompt_tokens'],
                        output_tokens=usage_metadata['candidates_tokens'],
                        total_tokens=usage_metadata['total_tokens'],
                        model="gemini-2.5-flash-lite",
                        details=f"ì²­í¬ {chunk_id} (í˜ì´ì§€ {start_page}-{end_page})"
                    )
                
                markdown = response.text.strip()
                
                # ê¸¸ì´ ì œí•œ (ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ ê²°ê³¼ ë°©ì§€)
                MAX_CHUNK_LENGTH = 50000  # 50,000ì ì œí•œ
                if len(markdown) > MAX_CHUNK_LENGTH:
                    logger.warning(f"   âš ï¸ ì²­í¬ {chunk_id} ê²°ê³¼ê°€ ë„ˆë¬´ ê¹€ ({len(markdown):,}ì) â†’ {MAX_CHUNK_LENGTH:,}ìë¡œ ìë¦„")
                    markdown = markdown[:MAX_CHUNK_LENGTH]
                
                # ë°˜ë³µ íŒ¨í„´ ì œê±° (ê°™ì€ í…ìŠ¤íŠ¸ê°€ 3ë²ˆ ì´ìƒ ë°˜ë³µë˜ë©´ ì œê±°)
                markdown = self._remove_repetitions(markdown)
                
                # ì—…ë¡œë“œëœ íŒŒì¼ ì‚­ì œ
                try:
                    genai.delete_file(uploaded_file.name)
                except:
                    pass
                
                logger.info(f"   âœ… ì²­í¬ {chunk_id} ì™„ë£Œ (í˜ì´ì§€ {start_page}-{end_page}, {len(markdown)}ì)")
                return (chunk_id, markdown, usage_metadata)

            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(tmp_path)

        except Exception as e:
            logger.error(f"   âŒ ì²­í¬ {chunk_id} ì‹¤íŒ¨: {e}")
            return (chunk_id, "", None)

    async def parse_pdf(
        self,
        file_bytes: bytes,
        filename: str,
        max_pages: Optional[int] = None,
        pages_per_chunk: int = 5  # 5í˜ì´ì§€ì”© ì²˜ë¦¬ (API í˜¸ì¶œ ìµœì í™”)
    ) -> dict:
        """
        PDFë¥¼ Markdownìœ¼ë¡œ ë³€í™˜ (5í˜ì´ì§€ì”© ë³‘ë ¬ ì²˜ë¦¬)

        Args:
            file_bytes: PDF íŒŒì¼ ë°”ì´íŠ¸
            filename: íŒŒì¼ëª…
            max_pages: ìµœëŒ€ ì²˜ë¦¬ í˜ì´ì§€ (í…ŒìŠ¤íŠ¸ìš©)
            pages_per_chunk: ì²­í¬ë‹¹ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ 5í˜ì´ì§€)

        Returns:
            {
                'markdown': str,
                'totalPages': int,
                'processingTime': float
            }
        """
        from pypdf import PdfReader, PdfWriter

        start_time = time.time()

        logger.info(f"ğŸš€ Gemini PDF íŒŒì‹± ì‹œì‘: {filename}")
        logger.info(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {len(file_bytes) / 1024 / 1024:.2f}MB")

        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (í˜ì´ì§€ ìˆ˜ í™•ì¸ìš©)
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(file_bytes)
                tmp_path = tmp_file.name

            try:
                # í˜ì´ì§€ ìˆ˜ í™•ì¸
                reader = PdfReader(tmp_path)
                total_pages = len(reader.pages)

                # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
                if max_pages and max_pages < total_pages:
                    total_pages = max_pages
                    logger.info(f"âš ï¸  í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {max_pages}í˜ì´ì§€ë§Œ ì²˜ë¦¬")

                logger.info(f"ğŸ“„ ì´ {total_pages}í˜ì´ì§€ â†’ {pages_per_chunk}í˜ì´ì§€ì”© ë³‘ë ¬ ì²˜ë¦¬")

                # í˜ì´ì§€ ì²­í¬ë¡œ ë¶„í• 
                chunks: List[tuple] = []
                for i in range(0, total_pages, pages_per_chunk):
                    start = i
                    end = min(i + pages_per_chunk - 1, total_pages - 1)
                    chunk_id = i // pages_per_chunk + 1
                    
                    # ì²­í¬ìš© PDF ìƒì„±
                    writer = PdfWriter()
                    for page_num in range(start, end + 1):
                        writer.add_page(reader.pages[page_num])
                    
                    # ë°”ì´íŠ¸ë¡œ ë³€í™˜
                    chunk_tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.pdf')
                    writer.write(chunk_tmp)
                    chunk_tmp.close()
                    
                    with open(chunk_tmp.name, 'rb') as f:
                        chunk_bytes = f.read()
                    
                    os.unlink(chunk_tmp.name)
                    
                    chunks.append((chunk_bytes, chunk_id, start + 1, end + 1))

                logger.info(f"âš¡ {len(chunks)}ê°œ ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘...")

                # ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 10ê°œì”© ë°°ì¹˜)
                max_concurrent = 10
                all_results = []
                
                for batch_start in range(0, len(chunks), max_concurrent):
                    batch = chunks[batch_start:batch_start + max_concurrent]
                    batch_num = batch_start // max_concurrent + 1
                    total_batches = (len(chunks) + max_concurrent - 1) // max_concurrent
                    
                    logger.info(f"   ğŸ”„ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ ì²­í¬)...")
                    
                    tasks = [
                        self._parse_pdf_chunk(chunk_bytes, chunk_id, start, end)
                        for chunk_bytes, chunk_id, start, end in batch
                    ]
                    
                    batch_results = await asyncio.gather(*tasks)
                    all_results.extend(batch_results)

                # ê²°ê³¼ ì •ë ¬ ë° ë³‘í•©
                all_results.sort(key=lambda x: x[0])  # chunk_idë¡œ ì •ë ¬
                markdown = "\n\n".join([text for _, text, _ in all_results if text])
                
                # í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„
                total_prompt_tokens = 0
                total_candidates_tokens = 0
                total_tokens = 0
                
                for _, _, usage in all_results:
                    if usage:
                        total_prompt_tokens += usage.get('prompt_tokens', 0)
                        total_candidates_tokens += usage.get('candidates_tokens', 0)
                        total_tokens += usage.get('total_tokens', 0)

            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(tmp_path)

            processing_time = time.time() - start_time

            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ!")
            logger.info(f"ğŸ“ ê²°ê³¼ í¬ê¸°: {len(markdown) / 1024:.2f}KB")
            logger.info(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ ({len(chunks)}ê°œ ì²­í¬ ë³‘ë ¬)")
            
            # ì´ í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥
            if total_tokens > 0:
                print(f"\n{'=' * 60}")
                print(f"ğŸ’° ì´ í† í° ì‚¬ìš©ëŸ‰ (PDF íŒŒì‹±)")
                print(f"   ì…ë ¥ í† í°: {total_prompt_tokens:,}")
                print(f"   ì¶œë ¥ í† í°: {total_candidates_tokens:,}")
                print(f"   ì´ í† í°: {total_tokens:,}")
                print(f"{'=' * 60}\n")
                
                logger.info(f"ğŸ’° ì´ í† í° ì‚¬ìš©ëŸ‰ - ì…ë ¥: {total_prompt_tokens:,}, ì¶œë ¥: {total_candidates_tokens:,}, ì´í•©: {total_tokens:,}")
                
                # CSVì— ì´í•© ê¸°ë¡
                log_token_usage(
                    operation="PDFíŒŒì‹±_ì´í•©",
                    prompt_tokens=total_prompt_tokens,
                    output_tokens=total_candidates_tokens,
                    total_tokens=total_tokens,
                    model="gemini-2.5-flash-lite",
                    details=f"{filename} ({total_pages}í˜ì´ì§€, {len(chunks)}ì²­í¬)"
                )

            return {
                'markdown': markdown,
                'totalPages': total_pages,
                'processingTime': processing_time,
                'tokenUsage': {
                    'promptTokens': total_prompt_tokens,
                    'candidatesTokens': total_candidates_tokens,
                    'totalTokens': total_tokens
                }
            }

        except Exception as e:
            logger.error(f"âŒ Gemini PDF íŒŒì‹± ì˜¤ë¥˜: {e}")
            raise Exception(f"PDF íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
gemini_pdf_service = GeminiPDFService()
