"""
ì„¹ì…˜ ì „ì²˜ë¦¬ ëª¨ë“ˆ
Gemini Vision ê¸°ë°˜ PDF ì„¹ì…˜ ì „ì²˜ë¦¬ ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
"""
from PyPDF2 import PdfReader, PdfWriter
from langchain.docstore.document import Document
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from .vision_processor import VisionProcessor
from .chunker import DocumentChunker
from config import embedding_settings as config


class SectionPreprocessor:
    """ì„¹ì…˜ ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, model_name: str = None):
        """
        ì´ˆê¸°í™”

        Args:
            model_name: LLM ëª¨ë¸ëª… (Gemini Vision ëª¨ë¸)
        """
        self.model_name = model_name or config.DEFAULT_LLM_MODEL
        self.vision_processor = VisionProcessor(model_name)
        self.chunker = DocumentChunker()

    def extract_pdf_section(self, pdf_path: str, start_page: int, end_page: int) -> str:
        """PDFì—ì„œ íŠ¹ì • í˜ì´ì§€ ë²”ìœ„ë§Œ ì¶”ì¶œí•˜ì—¬ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥"""
        reader = PdfReader(pdf_path)
        writer = PdfWriter()

        for page_num in range(start_page - 1, min(end_page, len(reader.pages))):
            writer.add_page(reader.pages[page_num])

        temp_path = f"{config.TOC_SECTIONS_DIR}/section_{start_page}_{end_page}.pdf"
        with open(temp_path, "wb") as output_file:
            writer.write(output_file)

        return temp_path

    def preprocess_section(self, section: dict, pdf_path: str) -> dict:
        """
        ì„¹ì…˜ì„ ì „ì²˜ë¦¬í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        """
        try:
            self.extract_pdf_section(
                pdf_path,
                section.get("start_page", 1),
                section.get("end_page", 1)
            )
        except Exception as e:
            print(f"   âš ï¸  ì„¹ì…˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "vectorstore": None,
                "documents": [],
                "table_count": 0
            }

        try:
            print(f"\nğŸ“„ [{section.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')}] Gemini Visionìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì‹œì‘...")
            markdown_results = self.vision_processor.convert_section_to_markdown(
                pdf_path,
                section.get('start_page', 1),
                section.get('end_page', 1)
            )

            if not markdown_results:
                print(f"   âš ï¸  ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    "vectorstore": None,
                    "documents": [],
                    "table_count": 0
                }

            print(f"   âœ… {len(markdown_results)}ê°œ í˜ì´ì§€ ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸  ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
            return {
                "vectorstore": None,
                "documents": [],
                "table_count": 0
            }

        split_docs = []
        table_count = 0

        for page_num, markdown_text in markdown_results:
            try:
                page_docs = self.chunker.chunk_markdown_with_dual_chunking(
                    markdown_text,
                    page_number=page_num
                )

                for doc in page_docs:
                    doc.metadata.update({
                        'section_title': section.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                        'section_start': section.get('start_page', 1),
                        'section_end': section.get('end_page', 1)
                    })

                    if doc.metadata.get('type') == 'table':
                        table_count += 1

                    split_docs.append(doc)
            except Exception as e:
                print(f"   âš ï¸  í˜ì´ì§€ {page_num} Dual Chunking ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                try:
                    fallback_doc = Document(
                        page_content=markdown_text,
                        metadata={
                            'section_title': section.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ'),
                            'section_start': section.get('start_page', 1),
                            'section_end': section.get('end_page', 1),
                            'page_number': page_num,
                            'type': 'text',
                            'chunk_type': 'page',
                            'is_table': False
                        }
                    )
                    split_docs.append(fallback_doc)
                except Exception:
                    pass

        try:
            if not split_docs:
                print(f"   âš ï¸  ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                embeddings = GoogleGenerativeAIEmbeddings(model=config.DEFAULT_EMBEDDING_MODEL)
                empty_doc = Document(page_content="", metadata={})
                vectorstore = FAISS.from_documents(documents=[empty_doc], embedding=embeddings)
            else:
                embeddings = GoogleGenerativeAIEmbeddings(model=config.DEFAULT_EMBEDDING_MODEL)
                vectorstore = FAISS.from_documents(documents=split_docs, embedding=embeddings)
        except Exception as e:
            print(f"   âš ï¸  ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            try:
                embeddings = GoogleGenerativeAIEmbeddings(model=config.DEFAULT_EMBEDDING_MODEL)
                empty_doc = Document(page_content="", metadata={})
                vectorstore = FAISS.from_documents(documents=[empty_doc], embedding=embeddings)
            except Exception:
                vectorstore = None

        return {
            "vectorstore": vectorstore,
            "documents": split_docs if split_docs else [],
            "table_count": table_count
        }
